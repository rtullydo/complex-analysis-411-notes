<?xml version="1.0" encoding="UTF-8" ?>

<pretext xmlns:xi="http://www.w3.org/2001/XInclude">

    <docinfo>
        <macros>
        \DeclareMathOperator{\RE}{Re}
          \DeclareMathOperator{\IM}{Im}
          \DeclareMathOperator{\ess}{ess}
          \DeclareMathOperator{\intr}{int}
          \DeclareMathOperator{\dist}{dist}
          \DeclareMathOperator{\dom}{dom}
          \DeclareMathOperator{\diag}{diag}
          \DeclareMathOperator{\rank}{rank}
          \DeclareMathOperator{\col}{col}
          \DeclareMathOperator{\cl}{cl}
          \DeclareMathOperator{\row}{row}
          \DeclareMathOperator{\proj}{proj}
          \DeclareMathOperator{\ball}{ball}
          \DeclareMathOperator{\gd}{grad}
          \DeclareMathOperator{\Log}{Log}
          \DeclareMathOperator{\Arg}{Arg}
          \DeclareMathOperator\re{\mathrm {Re~}}
          \DeclareMathOperator\im{\mathrm {Im~}}
          %\newcommand\half{\tfrac 12}
          \newcommand{\eps}{\varepsilon}
          \newcommand{\To}{\longrightarrow}
          \newcommand{\hilbert}{\mathcal{H}}
          \newcommand{\s}{\mathcal{S}_2}
          \newcommand{\A}{\mathcal{A}}
          \newcommand\h{\mathcal{H}}
          \newcommand{\J}{\mathcal{J}}
          \newcommand{\F}{\mathbb{F}}
          \newcommand{\K}{\mathcal{K}}
          \newcommand{\N}{\mathcal{N}}
          \newcommand{\T}{\mathbb{T}}
          \newcommand{\W}{\mathcal{W}}
          \newcommand{\X}{\mathcal{X}}
          \newcommand{\Y}{\mathcal{Y}}
          \newcommand{\D}{\mathbb{D}}
          \newcommand{\C}{\mathbb{C}}
          \newcommand{\BOP}{\mathbf{B}}
          \newcommand{\Z}{\mathbb{Z}}
          \newcommand{\BH}{\mathbf{B}(\mathcal{H})}
          \newcommand{\KH}{\mathcal{K}(\mathcal{H})}
          \newcommand{\pick}{\mathcal{P}_2}
          \newcommand{\schur}{\mathcal{S}_2}
          \newcommand{\R}{\mathbb{R}}
          \newcommand{\Complex}{\mathbb{C}}
          \newcommand{\Field}{\mathbb{F}}
          \newcommand{\RPlus}{\Real^{+}}
          \newcommand{\Polar}{\mathcal{P}_{\s}}
          \newcommand{\Poly}{\mathcal{P}(E)}
          \newcommand{\EssD}{\mathcal{D}}
          \newcommand{\Lop}{\mathcal{L}}
          \newcommand{\cc}[1]{\overline{#1}}
          \newcommand{\abs}[1]{\vert#1\vert}
          \newcommand{\set}[1]{\left\{#1\right\}}
          \newcommand{\seq}[1]{\left\lt#1\right>}
          \newcommand{\norm}[1]{\left\Vert#1\right\Vert}
          \newcommand{\essnorm}[1]{\norm{#1}_{\ess}}
          \newcommand{\tr}{\operatorname{tr}}
          \newcommand{\ran}[1]{\operatorname{ran}#1}
          \newcommand{\nt}{\stackrel{\mathrm {nt}}{\to}}
          \newcommand{\pnt}{\xrightarrow{pnt}}
          \newcommand{\ip}[2]{\left\langle #1, #2 \right\rangle}
          \newcommand{\ad}{^\ast}
          \newcommand{\inv}{^{-1}}
          \newcommand{\adinv}{^{\ast -1}}
          \newcommand{\invad}{^{-1 \ast}}
          \newcommand\Pick{\mathcal P}
          \newcommand\Ha{\mathbb{H}}
          \newcommand{\HH}{\Ha\times\Ha}
          \newcommand\Htau{\mathbb{H}(\tau)}
          \newcommand{\vp}{\varphi}
          \newcommand{\ph}{\varphi}
            \newcommand{\th}{\vartheta}
          \newcommand\al{\alpha}
          \newcommand\ga{\gamma}
          \newcommand\de{\delta}
          \newcommand\ep{\varepsilon}
          \newcommand\la{\lambda}
          \newcommand\up{\upsilon}
          \newcommand\si{\sigma}
          \newcommand\beq{\begin{equation}}
          \newcommand\ds{\displaystyle}
          \newcommand\eeq{\end{equation}}
          \newcommand\df{\stackrel{\rm def}{=}}
          \newcommand\ii{\mathrm i}
          \newcommand\net[1]{\langle #1 \rangle}
          \newcommand{\vectwo}[2]
          {
             \begin{pmatrix} #1 \\ #2 \end{pmatrix}
          }
          \newcommand{\vecthree}[3]
          {
             \begin{pmatrix} #1 \\ #2 \\ #3 \end{pmatrix}
          }
          \newcommand\blue{\color{blue}}
          \newcommand\black{\color{black}}
          \newcommand\red{\color{red}}
          %\newcommand\red{\color{black}}
          \newcommand\nn{\nonumber}
          \newcommand\bbm{\begin{bmatrix}}
          \newcommand\ebm{\end{bmatrix}}
          \newcommand\bpm{\begin{pmatrix}}
          \newcommand\epm{\end{pmatrix}}
          \numberwithin{equation}{section}
          \newcommand\nin{\noindent}
          \newcommand{\nCr}[2]{\,_{#1}C_{#2}} % nCr
          \newcommand{\ps}{\displaystyle \sum_{n=0}^\infty a_n x^n}
          \newcommand{\psg}{\displaystyle \sum_{n=0}^\infty b_n x^n}
          \newcommand{\hz}{\,\mathrm{Hz}}
          \newcommand{\dd}{^\prime}
        </macros>
    </docinfo>

<book xml:id="comp411">
    <title>Notes on complex analysis</title>
    <frontmatter>

        <titlepage>
            <author>
              <personname>Ryan Tully-Doyle</personname>
              <institution>Cal Poly, SLO</institution>
            </author>
            <date><today /></date>
        </titlepage>
    </frontmatter>


    <chapter><title>Conformal maps and linear fractional transformations</title>
    <section>
        <title>Conformal maps</title>
        <p>Certain functions behave like little rigid rotations locally.
            <definition>
                A function <m>f: A \to B</m> is called <term>conformal</term> if for each <m>z_0 \in A</m>, <m>f</m> rotates tangent vectors to curves passing through <m>z_0</m> by a fixed angle <m>\theta</m> and stretches tangent vectors to curves by a fixed factor <m>r</m>.
            </definition>
        </p>

        <p>By way of example, consider the function <m>f(z) = z^2</m> at the point <m>z_0 = 1 + 1i = \sqrt{2}e^{i\pi/4}</m>. The horizontal line through <m>z_0</m> can be parametrized by <m>\gamma(t) = (1 + t) + 1i</m> which passes through <m>z_0</m> at <m>t = 1</m>. The tangent vector at <m>t = 1</m> is <m>\gamma\dd(0) = 1</m>. Now look at the image. Composing, we get
            <me>
                f(\gamma(t)) = (t + 1i)^2 = (t^2 - 1)  + 2ti.
            </me> 
        Then calculating the tangent vector to the image gives
            <me>
                f\dd(\gamma(t))|_{t = 1} = (2t + 2i)|_{t =1} = 2 + 2i.
            </me>
            That is, the tangent vector has increased in length by a factor of <m>2\sqrt{2}</m> and undergone a rotation of <m>\pi/4</m> radians. If we check the vertical line through <m>z_0</m>, which can be parametrized by <m>\gamma_2(t) = 1 + 1ti</m> where <m>\gamma_2(1) = z_0</m>, we find that the tangent vector <m>\gamma_2(1) = i</m> has image <m>f(\gamma_2(1)) = -2 + 2i</m>, which again represents an increase in magnitude of <m>2\sqrt{2}</m> and a rotation of <m>\pi/4</m> radians.
        </p>

        <p>There is a close connection between analytic maps and conformal maps.</p>
        <theorem>
            <p>Let <m>f: A \to B</m> be analytic and let <m>f^\prime(z_0) \neq 0</m> for all <m>z_0 \in A</m>. Then <m>f</m> is conformal.</p>.
        </theorem>
        <p>This is pretty straighforward to see via the chain rule. Let <m>\gamma(t)</m> be a (differentiable) path contained in <m>A</m> with <m>\gamma(0) = z_0</m>. Let <m>\sigma(t)</m> be the image of <m>\gamma</m> under <m>f</m> defined by <m>\sigma(t) = f(\gamma(t))</m>. Then the chain rule gives
        <me>
            \sigma\dd(t) = f\dd(\gamma(t)) \cdot \gamma\dd(t)
        </me>
        which in turn gives
        <me>
            \sigma\dd(0) = f\dd(z_0) \cdot \gamma\dd(0).
        </me>
        That is, if <m>f\dd(z_0) = r e^{i \theta}</m> the image of the derivative of any curve <m>\gamma</m> through <m>z_0</m> is rotated by <m>\theta</m> and stretched by <m>r</m>.
        </p>

        <p>Note that the condition that <m>f\dd(z_0) \neq 0</m> is necessary. For one, it obviously covers up the relationship between a curve and its image in the relation above. But the problem is deeper. Consider the function <m>f(z) = z^2</m>. Consider the lines that run along the <m>x-</m> and <m>y-</m>axis. These lines cross at a right angle at <m>z = 0</m>, but since both lines are mapped to the real axis under <m>f</m>, their images intersect at an angle of <m>\pi</m> radians. For this reason, points at which <m>f\dd(z_0) = 0</m> are called <term>singular</term> and do not correspond to points of local conformality.</p>

        <p>Much of the behavior of analytic functions should be thought about in small neighborhoods around points. The next theorem is one that you learn in first year calculus and describes the relationship between the derivative of a function and the derivative of its inverse (when that inverse exists). Analytic functions away from singular points are <em>locally invertible</em>.</p>

        <theorem><title>Inverse function theorem</title>
            <p>Let <m>f:A \to \C</m> be analytic and <m>f\dd(z_0) \neq 0</m> for <m>z_0 \in A</m>. Then there exists a neighborhood <m>U</m> of <m>z_0</m> and a neighborhood <m>V</m> of <m>f(z_0)</m> so that
            <ol>
                <li>the restriction <m>f:U \to V</m> is a bijection,</li>
                <li><m>f\inv:V \to U</m> is analytic,</li>
                <li>and 
                    <me> \frac{d}{dw} f\inv(w) = \frac{1}{f\dd(z)} </me>
                    where <m>w = f(z)</m>.
                </li>
            </ol>
            </p>
        </theorem>

        <p>The inverse function theorem will let us make more connections between conformal maps and their inverses.</p>

        <proposition>
            <p>If a map <m>f:A \to B</m> is conformal and bijective, then <m>f\inv:B \to A</m> is conformal and bijective.</p>
        </proposition>
        <proof>
            <p>Because <m>f</m> is bijective, <m>f\inv</m> exists. Because <m>f</m> is conformal, for any <m>z \in A</m>, we must have <m>f\dd(z) \neq 0</m>. Then the inverse function theorem gives that <m>f\inv</m> is analytic and
            <me> \frac{d}{dw} f\inv(w) = \frac{1}{f\dd(z)} \neq 0, </me>
            and so <m>f\inv</m> is also conformal.</p>
        </proof>

        <proposition>
            <p>If <m>f:A \to B</m> is conformal and bijective and <m>g: B \to C</m> is conformal and bijective, then <m> g\circ f</m> is conformal and bijective.</p>
        </proposition>
        <proof>
            <p>This is an immediate consequence of the chain rule.</p>
        </proof>

        <p>Because conformality is preserved by inverses and composition, we have the structure necessary to impose ideas from algebra on the family of conformal maps if we can make the functions compatible. An <term>automorphism</term> is a bijection from a set onto itself.</p>

        <theorem>
            <p>The set of bijective conformal maps from a domain <m>A</m> to itself (that is, the set of conformal automorphisms of <m>A</m>) is a group, where the group operation is composition of functions.</p>
        </theorem>

        <p>As part of our study of conformal maps, we're going to be looking a special family of automorphisms defined on the unit disk <m>\D</m>, but that's for later!</p>

        <p>A typical use of bijective conformal maps is to change problems in one domain to problems in a different domain. It might not be obvious why, but frequently we can use tools in one domain that might not be available in another. Because bijective conformal maps preserve information about paths, solving a problem in one domain can be easily extended to a solution in a conformal relative.</p>

        <definition>
            <p> Two domains <m>A, B \subset \C</m> are called <term>conformally equivalent</term> if there is a bijective conformal map <m>f: A \to B</m>.</p>
        </definition>

        <theorem>
            <p>Let <m>A</m> be a simply connected domain that isn't all of <m>\C</m>. Then there exists a bijective conformal map <m>f: A \to \D</m>. Futher, for any fixed <m>z_0 \in A</m>, we can find <m>f</m> so that <m>f(z_0) = 0</m> and <m>f\dd(z_0) > 0</m>. With these conditions, the map <m>f</m> is unique.</p>
        </theorem>

        <p>There is a pretty easy but very striking corollary.</p>

        <corollary> 
            <p>Any two simply connected domains, neither of which is all of <m>\C</m>, are conformally equivalent.</p>
        </corollary>

        <p>Of course there are some annoyances here: we have no clue how to actually find the maps! We also don't know what happens at the boundary of the domains in the general case. Our next steps will be to address these questions.</p>
    </section>

    <section>
        <title> Simply connected sets, boundaries, and the Riemann mapping theorem</title>
        <p>
            Before we go on, we're going to need to deal with the issue that analytic maps don't always act nicely on the boundaries of their domains. (Remember, analytic and holomorphic are local properties defined on open sets, and the <q>edge</q> of a set isn't open.) Let us recall that a set is called <term>simply connected</term> if it <q>has no holes in it</q>. This intuitive idea of no holes corresponds to the rigorous notion a simply connected set is one in which every simple closed curve can be continuously deformed into a point without leaving the set. The act of continuously deforming a curve within a set is called <term>homotopy</term>. Two curves are said to be <term>homotopic</term> if we can find a homotopy from one curve to the other. More precisely, a homotopy in a domain <m>A</m> from a curve <m>\gamma_1</m> to a a curve <m>\gamma_2</m> is a continuous function <m>H(s, t)</m> where <m>H(s, t) \subset A</m> for all <m>s \in [0,1]</m>, and the endpoints have <m>H(0,t) = \gamma_1(t)</m>, and <m>H(1, t) = \gamma_2(t)</m>.
        </p>

        <p>Two domains <m>A, B \subset \C</m> are said to be <term>conformally equivalent</term> if there exists a bijective conformal map <m>f: A \to B</m>. The next theorem characterizes which sets are conformally equivalent to simply connected sets.</p>

        <theorem>
            <title>Riemann Mapping Theorem</title>
            <p>Let <m>A</m> be a simply connected domain in <m>\C</m> with <m>A \neq \C</m>. Then there exists a bijective conformal map <m>f: A \to \D</m>, where <m>\D</m> is the complex unit disk. For any fixed <m>z_0 \in A</m>, we can find a unique such <m>f</m> so that <m>f(z_0) = 0</m> and <m>f\dd(z_0) > 0</m>.</p>
        </theorem>

        <p>Because the maps in the theorem above are bijections, we get a striking immediate corollary.</p>

        <corollary>
            <p>Any two simply connected regions, neither one of which is all of <m>\C</m>, are conformally equivalent.</p>
        </corollary>

        <p>This is a powerful fact! Unfortunately, this theorem doesn't tell us how to fund the conformal maps that connect different sets. We'll take a deeper dive into that in the next couple of lectures.</p>

        <p>Now, we'll turn to the question of what happens to the boundaries of domains under conformal maps. One way to think of the boundary of a domain <m>A</m> in <m>\C</m> is the set of points that can be reached as limits of sequences in <m>A</m>. Another is to think of it as the set of points for which any neighborhood contains points in <m>A</m> and points outside of <m>A</m>. We use the notation <m>\partial A</m> to indicated the boundary of <m>A</m>. Because domains in <m>\C</m> are open, a set and its boundary are disjoint. The <term>closure</term> of a domain <m>A</m> is <m>A \cup \partial A</m> and will be denoted <m>cl(A)</m> (we can also use <m>\cc{A}</m>, but to avoid confusion with the complex conjugate, we'll avoid that in these notes).</p>

        <proposition>
            <p>Let <m>A, B</m> be domains in <m>\C</m> with boundaries <m>\partial A, \partial B</m>. Suppose that <m>f: A \to f(A)</m> is conformal (that is, <m>f</m> is conformal from its domain to its range). If <m>f(A)</m> has boundary <m>\partial B</m> and additionally <m>f(z_0) \in B</m> for some <m>z_0 \in A</m>, then <m>f(A) = f(B)</m>.</p>
        </proposition>

        <p>Essentially, the previous proposition implies that we can find the image of a conformal map by computing the image of the boundary and keeping track of where the interior of the domain was mapped via a single point.</p>

        <p>We now come to the question of when a conformal map between domains can be extended to the boundary. Note that this extension will be a <em>continuous</em> extension, not an analytic one, because we can't work on neighborhoods for points in the boundary. For nice sets, conformal maps do indeed extend to the boundary.</p>

        <theorem>
            <p>Suppose that <m>A, B</m> are bounded, simply connected regions with boundaries <m>\partial A</m> and <m>\partial B</m> that are simple, continuous, closed curves (these are sometimes called Jordan curves). Then any conformal map of <m>A</m> that is one-to-one onto <m>B</m> can be extended to a continuous map of <m>A \cup \partial A</m> one-to-one onto <m>B \cup \partial B</m>.</p>
        </theorem>

        <question>
            <p>Find a bijective conformal map that takes a bounded region to an unbounded region. Show that there is no bijective conformal map from a simply connected domain to a non-simply connected domain.</p>
        </question> 
    </section>

    <section>
        <title>(optional) A proof of the Riemann Mapping Theorem</title>
        <p>The Riemann Mapping Theorem asserts that a simply connected domain <m>A</m> is conformally equilvalent to the complex unit disk <m>\D</m>. To prove this is going to take a bit of work, so roll up your sleeves! We'll proceed in pieces.</p>

        <p>A sequence of functions <m>f_n</m> is said to be <term>locally uniformly bounded</term> on a domain <m>A</m> if, for any <m>z_0 \in A</m>, there exists a neighborhood <m>U</m> of <m>z_0</m> and a constant <m>M</m> so that <m>\abs{f_n} \lt M</m> on <m>U</m> for all <m>n</m>. Equivalently, a sequence of functions is locally uniformly bounded if the family of functions is uniformly bounded on each compact subset of the domain.</p>

        <theorem><title>Stieljes-Osgood Theorem</title>
            <p>A locally uniformly bounded sequences of holomorphic functions on a domain <m>A \subset \C</m>, has a locally uniformly convergent subsequence.</p>
        </theorem>

        <proof>
            <p>Let <m>A</m> be the domain of the sequence of locally uniformly bounded functions <m>\{f_n\}_{n=1}^\infty</m>.</p>

            <p>It is enough to show that for each closed disk <m>D</m> in <m>A</m> that the sequence <m>f_n</m> converges uniformly on <m>D</m>. Suppose we could do so. Then we could take a countable cover of <m>A</m> by open disks whose closures <m>cl(D_k) \subset A</m> (say by using points with rational real and imaginary parts as centers), which can be arranged into a sequence <m>\{D_k\}</m>. Then by supposition, the sequence <m>f_n</m> has a subsequence <m>f_{1,n}</m> converging uniformly on <m>D_1</m>. Applying the same argument to <m>f_{1,n}</m> on <m>D_2</m> gives a subsequence converging uniformly on <m>D_2</m> (and <m>D_1</m>). Proceed inductively. The sequence <m>f_{k,n}</m> will be a subsequence of every previous subsequence, including <m>f_{n}</m>. Now take the sequence of elements <m>f_{n,n}</m>. It is a subsequence of <m>f_n</m> and it is locally uniformly convergent in <m>A</m>. (This is a form of a <q>diagonal</q> argument, ala Cantor.)</p>

            <p>We can reduce the problem even further. Consider one of the disks, say <m>D_k</m>. Because <m>cl(D_k)</m> is a subset of then open set <m>A</m>, it is contained in an open disk <m>U</m> also contained in <m>A</m> and with <m>cl(U) \subset A</m> on which <m>f_n</m> is uniformly bounded.</p>
        </proof>

    </section>

    <section>
        <title>Interlude: Liouville's Theorem</title>
        <p>In the calculus of real functions, it isn't at all unusual to deal with power series that converge everywhere in <m>\R</m> that represent bounded functions. (A whole class of these in the real world are signals that can be expressed as Fourier series). For example, <m>f(x) = \sin x</m> has a power series representation valid for all real <m>x</m> and it bounded in absolute value by 1. The extension theorem tells us that this same series should have infinite radius of convergence on <m>\C</m> as well, but we should note what happens to the size of the values of the function. Let <m> z = x + iy</m>. Then
        <me>
            f(z) = \sin z = \frac{1}{2i} (e^{iz} - e^{-iz}),
        </me>
        and
        <me>
            e^{iz} = e^{ix - y} = e^{ix} e^{-y}
        </me>
        which will be unbounded as we let <m>y \to -\infty</m>. So even though <m>\sin z</m> remains a function with a convergent power series representation on <m>\C</m> (a so-called <term>entire</term> function), it is an unbounded function. Liouville's theorem asserts that this is the general situation - an entire function that is bounded must necessarily be a constant function.</p>

        <p>The proof of Liouville's theorem follows from a useful set of estimates about the behavior of derivatives of bounded analytic functions called the Cauchy inequalities. First, recall that Cauchy's integral theorem for derivatives gives
            <me>
                f^{n}(z_0) = \frac{n!}{2\pi i} \oint_C \frac{f(z)}{(z - z_0)^{n+1}} \, dz
            </me>
            where <m>C</m> is a simple closed curve about <m>z_0</m> inside the domain of <m>f</m>.</p>

        <theorem>
            <title>Cauchy inequalities</title>
            <p>Let <m>f</m> be an analytic function on a domain <m>A</m> with bound <m>\abs{f(z)} \lt M</m> on <m>A</m>, and let <m>\gamma</m> be a circle of radius <m>R</m> centered at a point <m>z_0 \in A</m> with <m>\gamma \subset A</m>. Then
            <me>
                \abs{f^{n}(z_0)} \leq \frac{n!}{R^n} M.
            </me></p>
        </theorem>

        <proof>
            <p>Suppose that <m>\gamma(t) = z_0 + R e^{it}</m> parametrizes <m>\gamma</m>. Note that restricted to <m>\gamma</m>, we have <m>z - z_0 = R</m>.  By the integral theorem for derivatives,  we have
            <md>
                <mrow> \abs{f^{n}(z_0)} \amp= | \frac{n!}{2\pi i} \oint_\gamma \frac{f(z)}{(z - z_0)^{n+1}} \, dz |</mrow> 
                <mrow>\amp= \frac{n!}{2\pi} |\oint_\gamma \frac{f(z)}{(z - z_0)^{n+1}} \, dz|</mrow>
                <mrow>\amp\leq \frac{n!}{2\pi} \frac{M}{R^{n+1}} 2 \pi R,</mrow>
                <mrow>\amp= \frac{n!}{R^n}M</mrow>
            </md>
            where the inequality follows from the ML-inequality.</p>
        </proof>

        <p>We're now ready for the main result of this section</p>

        <theorem>
            <title>Liouville's Theorem</title>
            <p>A bounded entire function is necessarily constant.</p>
        </theorem>

        <proof>
            <p>Let <m>z_0</m> be a complex number and let <m>\gamma</m> be a circle of radius <m>R</m> centered at <m>z_0</m>. Suppose that <m>f</m> is bounded in modulus on <m>\C</m> by a constant <m>M</m>. Now apply the Cauchy inequality with <m>n = 1</m> to <m>f</m> at <m>z_0</m>. This gives
            <me>
                |f\dd(z_0)| \leq \frac{M}{R}.
            </me>
            This inequality holds for all radii <m>R</m>, because every circle centered at <m>z_0</m> is contained in the domain of <m>f</m>. In particular, this means that as we let <m>R \to \infty</m>, we have
            <me>
                |f\dd(z_0)| = 0,
            </me>
            which means that <m>f\dd(z_0) = 0</m>. Since this holds for every <m>z_0 \in \C</m>, we have <m>f\dd(z) = 0</m> and so <m>f(z) = c</m> for some constant <m>c \in \C</m>.</p>
        </proof>


    </section>


    <section>
        <title>Exercise set 1</title>
        <exercises>
            <exercise>
                <p>Let <m>S</m> be the square with corners <m>(0,1), (1,1), (1, 2), (0,2)</m>. Find the image of the square under the map <m>f(z) = z^2</m>. Where does the interior of the square map? Is the image a square?</p>
            </exercise>
            <exercise>
                <p>Let <m>S</m> be the unit square in <m>\C</m>. Find the image of the square under the map <m>f(z) = z^2</m>. Make sure to indicate where the interior maps.</p>
            </exercise>
            <exercise>
                <p>Find the image of the first quadrant under the map <m>f(z) = z^3</m>.</p>
            </exercise>
            <exercise>
                <p>Let <m>z = x + iy</m>. Plot the set <m>A = \{xy>1 \text{ and } x, y >0\}</m>. Find the image of the set under the map <m>f(z) = z^2</m>.</p>
            </exercise>

            <exercise>
                <p>Near which points are the following functions conformal?
                    <ol>
                        <li> <m>f(z) = z/(1 + 2z)</m>;</li>
                        <li> <m>f(z) = \cc{z}</m></li>
                        <li> <m>f(z) = \tan z</m>.</li>
                    </ol>
                </p>
            </exercise>
            <exercise>
                <p>Let <m>a, b \in \C</m> be constant. Show that <m>f: \C \to \C</m> defined by <m>f(z) = az + b</m> can be written as a rotation followed by a magnification followed by a translation.</p>
            </exercise>
            <exercise>
                <p>The Riemann mapping theorem concerns simply connected sets that are not all of <m>\C</m>. Is there a conformal map from <m>\C</m> that is one-to-one onto the unit disk <m>\D</m>? Is there a conformal map of <m>\D</m> one-to-one onto <m>\C</m>?</p>
            </exercise>

        </exercises>
    </section>

    <section>
        <title>Linear fractional tranformations</title>
        <p>A couple of you have asked me how to actually find the conformal maps that are guaranteed to exist by the Riemann Mapping Theorem. For a large class of domains, we can readily (for some value of readily) find these!</p>

        <definition>
            <p>A <term>linear fractional transformation</term> is a degree one complex rational function of the form
            <me>
                T(z) = \frac{az + b}{cz + d}
            </me>
            for fixed constants <m>a, b, c, d \in \C</m>, and where we assume that <m>ad - bc \neq 0</m>.</p>
        </definition>

        <question>
            <p>What happens to <m>T</m> if <m>ad - bc \neq 0</m>?</p>
        </question>

        <p>We will use the shorthand LFT to stand for linear fractional transformation. From what we learned last term, it should be immediately obvious that an LFT has one pole of order 1 where <m>cz + d = 0</m>.</p>

         <p>LFTs are the basic building blocks of conformal maps.</p>

         <proposition xml:id="prop-lft">
            <p>Let 
                <me>
                    T(z) = \frac{az + b}{cz + d}.
                </me>
            Then <m>T</m> is bijective and conformal from <m>A = \{z: cz + d \neq 0\}</m> to <m>B = \{w: cw - a\neq 0\}</m>.</p>
            <p>The inverse function <m>T\inv:B \to A</m> is also a linear fractional tranformation with formula
                <me>
                    T\inv(w) = \frac{-dw + b}{cw - a}.
                </me></p>
        </proposition>

        <proof>
            <p>Let <m>S = \frac{-dw + b}{cw - a}</m>. The domain <m>A</m> excludes the simple pole of <m>T</m>, and likewise for <m>B</m> and <m>S</m>, which means that <m>T, S</m> are analytic on <m>A, B</m> respectively. So the argument comes down to showing that these functions are inverses, which can be done by direct computation. We will need the fact that <m>cw - a \neq 0</m> on <m>B</m> and that <m>bc - ad \neq 0</m> by definition. We leave to the reader the computation that
            <me>
                T(S(w)) = w
            </me>
            and
            <me>
                S(T(z)) = z
            </me>.
            Finally,
            <me>
                1 = \frac{d}{dz}(z) = \frac{d}{dz} (S(T(z))) = S\dd(T(z)) \cdot T\dd(z),
            </me>
            which implies that <m>T\dd(z) \neq 0.</m></p>
        </proof>

        <p>We leave a little hook for the future here - we can <q>complete</q> the function by assigning the value <m>T(-d/c) = \infty</m>, which will turn out, which a little caution, to give us a conformal bijection of the Riemann sphere to itself. We'll arrive at the Riemann sphere in the next section.</p>

        <p>What sort of functions are in the class of LFTs? If <m>a = 1, c = 0, d=0</m>, we get the translation function <m>T(z) = z + b</m>. If <m>b = c = 0</m> and <m>d = 1</m>, then we get <m>T(z) = az</m>, which should be viewed as <m>T(z) = re^{i\theta}z</m> which is a rotation by <m>\theta</m> and a magnification by <m>r</m>. Finally, if <m>b=c=1</m> and <m>a=d=0</m>, we get the inversion function <m>T(z) = \frac{1}{z}</m>.</p>

        <p>We noted that the conformal automorphisms of the unit disk form a group - let us characterize these functions.</p>

        <proposition>
            <p>A conformal automorphism of the unit disk <m>\D</m> is a linear fractional transformation of the form
            <men xml:id="eq-diskLFT">
                T(z) = e^{i\theta} \frac{z - \alpha}{1 - \cc\alpha z}
            </men>
            for a fixed angle <m>\theta \in [0, 2\pi)</m> and a fixed <m>\alpha \in \D</m>. Moreover, any <m>T</m> of this form is a conformal automorphism of <m>\D</m>.</p>
        </proposition>

        <proof>
            <p>We'll start by showing that maps of the form of <m>T</m> map the unit circle into itself. First, assume that <m>\abs{z} = 1</m>. Then
            <me>
                \abs{T(z)} = \abs{\frac{z - \alpha}{1 - \cc\alpha z}} = \frac{1}{\abs{z}} \abs{\frac{z - \alpha}{z\inv - \cc\alpha}}.
            </me>
            Because <m>\abs{z} = 1</m>, we also have that <m>z\inv = \cc z</m>, which gives
            <me>
                \abs{T(z)} = \frac{\abs{z - \alpha}}{\abs{\cc z - \cc \alpha}} = 1.
            </me>
            Hence, <m>T(\T) \subset \T</m>. Now, note that <m>T</m> has only a singularity at <m>z = \frac{1}{\cc\alpha}</m>, which is outside the unit circle, so <m>T</m> is analytic in a neighborhood of <m>\D</m>. Then by the maximium modulus principle, for any <m>z\in \D</m>, we must have <m>\abs{T(z)} \lt 1</m>, which implies that <m>T:\D \to \D</m>. Also, by <xref ref="prop-lft"/>, <m>T\inv</m> has the same form, and so also defines a conformal map from <m>\D \to \D</m>. Thus any such <m>T</m> is a conformal automorphism from <m>\D \to \D</m>.</p>

            <p>Now, let's show that any conformal automorphism from <m>\D \to \D</m> must be of this form. We'll be using uniqueness of conformal maps. Assume that <m>R:\D \to \D</m> is a conformal automorphism. Let <m>\alpha = R\inv(0)</m>, and let <m>\theta = \operatorname{arg} R\dd(z_0)</m>. A map <m>T</m> of the form <xref ref="eq-diskLFT"/> also has <m>T(\alpha) = 0</m>. Further, if we compute the derivative of <m>T</m> at <m>\alpha</m>, we'll get
            <me>
                T\dd(\alpha) =e^{i\theta} \frac{1}{1 - \abs{\alpha}^2}
            </me>,
            which has argument <m>\operatorname{arg} T\dd(\alpha) = \theta</m>. Thus, <m>R</m> and <m>T</m> agree in value and argument at <m>\alpha</m>, and so by uniquess of conformal maps, <m>R = T</m>. (note: the argument version of uniqueness follows from the positive derivative version. add this to a future draft or add as exercise.) </p>
        </proof>

        <p>Let <m>\hat\C</m> denote the extended complex plane. If we think of lines as passing through the unique point at <m>\infty</m> in either direction, then lines are essentially circles in <m>\hat\C</m>. Equivalently, lines map to great circles passing through the north pole in the Riemann sphere model. Linear fractional transforms on <m>\hat\C</m> send circles to circles with this identification for lines.</p>

        <proposition>
            <p>Let <m>T</m> be a linear fractional transformation. If <m>L \subset \C</m> is a line and <m>S \subset \C</m> is a circle, then <m>T(L)</m> is a line or a circle, and <m>T(S)</m> is a line or a circle.</p>
        </proposition>

        <p>Some authors use the amusingly awful word <q>clircle</q> to include both cases. We'll be more dignified and just say <q>circle</q> when we're referring to these shapes in the extended plane or sphere.</p>

        <p>Now suppose that we are given three points in <m>\C</m>. If these are collinear, the three points determine a unique line. If they are not collinear, they determine a unique circle. Because LFTs take circles/lines to circles lines, we might suspect that the implication of the geometric fact above is that there is a unique linear fractional map carrying any set <m>z_1, z_2, z_3 \in \C</m> to the set <m>w_1, w_2, w_3 \in \C</m>, and this is indeed the case.</p>

        <proposition>
            <p>Given two sets of distinct points <m>z_1, z_2, z_3</m> and <m>w_1, w_2, w_3</m>, there is a unique LFT with <m>T(z_i) = w_i</m> for <m>i = 1, 2, 3</m>. Moreover, if <m>T(z) = w</m> then
            <me>
                \frac{w - w_1}{w - w_2} \cdot \frac{w_3 - w_2}{w_3 - w_1} = \frac{z - z_1}{z - z_2}\cdot\frac{z_3 - z_2}{z_3 - z_1}.
            </me></p>
        </proposition>

        <figure>
            <caption>Useful conformal maps</caption>
            <image source="conmaps.jpg" />
        </figure>


    </section>

    <section>
        <title>Exercises 2</title>
        <exercises>
            <exercise>
                <p>Let <m>f(z) = (z-1)/(z+1)</m>. Find the image under <m>f</m> of the following sets:
                <ol>
                    <li>the real line;</li>
                    <li>the imaginary axis</li>
                    <li>the unit circle;</li>
                    <li>the circle centered a 0 with radius 2;</li>
                </ol></p>
            </exercise>

            <exercise>
                <p>Is the image of a triangle under a conformal map a triangle? Why or why not? How about on the sphere? (What is a <q>triangle</q> on a sphere?)</p>
            </exercise>

            <exercise>
                <p>Let <m>f(z) = (z- i)/(z+i)</m>. Find the image under <m>f</m> of the following sets:
                <ol>
                    <li>the real line;</li>
                    <li>the imaginary axis</li>
                    <li>the unit circle;</li>
                    <li>the circle centered a 0 with radius 2;</li>
                    <li>the triangle with vertices <m>0, i, 1+i \in \C</m>.</li>
                </ol></p>
            </exercise>
            <exercise>
                <p>Find a linear fractional transform that takes the unit disk to the right half plane with <m>f(0) = 2</m>.</p>
            </exercise>
            <exercise>
                <p>Find a linear fractional transform that takes the unit disk to itself and maps <m>1/2</m> to <m>1/3</m>.</p>
            </exercise>
            <exercise>
                <p>Determine the image of the unit disk under the map <m>f(z) = \frac{z+1}{3z + 1}</m>. Where is the image of the real axis? What about the imaginary axis?</p>
            </exercise>
            <exercise>
                <p>Find a conformal map taking the quarter of unit disk in the first quadrant to the entire unit disk. Hint: <m>f(z) = z^4</m> isn't good enough. Why? Can you do it with a bijective conformal map?</p> 
            </exercise>
            <exercise>
                <p>Show that a composition of two linear fractional maps is a linear fractional map.</p>
            </exercise>
        </exercises>
    </section>

    <section>
        <title>Reflection across a circle</title>
        <p>Recall that for the unit circle <m>\T</m>, we have the nice reflection map <m>z \mapsto 1/\cc{z}</m>, which maps an element <m>z\in \D</m> to its <term>reflection across the circle</term> <m>\tilde{z}</m>, which lies on the same ray - that is, the map <m>z \mapsto \tilde{z}</m> sends <me>r e^{i\theta} \mapsto \frac{1}{r} e^{i\theta}.</me> Notice then that the map <m>z \mapsto \tilde{z}</m> takes the disk <m>\D</m> to what we might call the outer disk <m>\tilde{\D}</m>. </p>

        <p>We're going to extend this idea to general circles (including lines, which should be thought of as circles of infinite radius in this context).</p>

        <proposition xml:id="proposition-existence-of-a-reflection-point">
            <title>Existence of a reflection point</title>
            <statement> Let <m>C</m> be a circle (or line), and let <m>z \notin C</m> be a point. Then the familiy of all circles passing through <m>z</m> that intersect <m>C</m> at right angles also intersect at a single point <m>\tilde{z}</m>.</statement>
        </proposition>

        <proof>
            <p>In the case where <m>C</m> is a line, the argument follows from basic geometry, and <m>\tilde{z}</m> is the point on the line perpendicular to <m>C</m> passing through <m>z</m> and equidistant to <m>C</m> with <m>z</m>.</p>

            <p>If <m>C</m> is a circle, then the interior of <m>C</m> is a disk, and we can conformally map this disk with a LFT <m>T</m> to the upper half plane, with the circle mapping to the real line (why?). Now the family of circles passing through <m>z</m> and orthogonal to <m>C</m> continue to pass through the point <m>w = T(z)</m> and remain orthogonal to the image of <m>C</m>. By the line case, these circles must also pass through the reflection <m>\tilde{w}</m>. Finally, we conclude that <m>T\inv(\tilde{w}) = \tilde{z}</m> is the reflection of <m>z</m>.</p>
        </proof>

        <proposition xml:id="proposition-">
             <title>LFTs preserve reflection</title>
             <statement>If <m>T</m> is a linear fractional tranform and <m>C</m> is a circle (or line), then <m>T(\tilde{z}) = \tilde{T}(z)</m>.</statement>
         </proposition>

         <p>The next proposition gives a formula for computing <m>\tilde{z}</m> in the case that <m>C</m> is a general circle, generalizing the map that sends <m>z \to 1/\cc{z}</m> for the unit circle. In the case that <m>C</m> is a line, we can just set <m>\tilde{z}</m> to be the perpendicular reflection across the line.</p>

         <proposition xml:id="proposition-reflection-formula">
             <title>Reflection formula</title>
             <statement>If <m>C</m> is a circle with center <m>z_0</m> and radius <m>R</m>, then the map <m>z \mapsto \tilde{z}</m> is a composition of LFTs and complex conjugation. A formula for the reflection is
             <me>
                \tilde{z} = \cc{\frac{\cc{z_0}z + R^2 - \abs{z_0}^2}{z - z_0}}
                </me>
             </statement>
         </proposition>

        <p>We conclude with the following proposition concerning the properties of the reflection map.</p>

        <proposition xml:id="proposition-properties-of-reflection">
            <title>Properties of reflection</title>
            <statement>
                <ol>
                <li><m>\tilde{\tilde{z}} = z</m></li>
                <li><m>z \mapsto \tilde{z}</m> preserves the magnitude of angles, but reverses orientation (just as conjugation does).</li>
                <li><m>z \mapsto \tilde{z}</m> maps circles to circles.</li>
                </ol>
            </statement>
        </proposition>
    </section>

    <section>
        <title>Conformal maps and harmonic equations</title>
        <subsection>
            <title>Vector fields and harmonic functions</title>


            <p>We'll recall some definitions. Let <m>A</m> be a domain in <m>\R^2</m> (which we will identify with <m>\C</m> when in the analytic setting). A <term>scalar field</term> on <m>A</m> is a function <m>u(x, y): A \to \R</m> - in this context, we'll think of such a function as assigning a value to each point in <m>A</m>.</p>

            <p>A <term>vector field</term> on <m>A</m> is a function <m>V:A \to \R^2</m> that assigns to each point in <m>A</m> a vector <m>V(x,y) = (v_1(x,y), v_2(x,y))</m>. If <m>u</m> happens to be continuously differentiable, then a natural vector field associated with <m>u</m> is given by the <term>gradient field</term> <m>\nabla u = \operatorname{grad} u = \ip{u_x}{u_y}</m>. Continuous gradient fields have the property that line integrals in the field are path independent (which should remind you of the Cauchy-Goursat theorem). A function <m>u</m> with continuous gradient field <m>\nabla u</m> is called a <term>potential function</term>.</p>

            <p>There is useful geometry connecting potentials and their gradient fields. Recall that a <term>level curve</term> for <m>u</m> is the set of points <m>(x,y) \in A</m> with <m>u(x,y) = C</m> for constants <m>C \in \R</m>. Given that the gradient vectors measure the direction of greatest change in a scalar field, it shouldn't be surprising that the gradient vector at a point in <m>A</m> is orthogonal to the level curve through the point. If the vector field varies continuously, we might expect that we can trace <term>flow lines</term> through <m>A</m>. A flow line (say parametrized by <m>\gamma</m>) should have the property that at every point <m>(x,y) \in A</m>, <m>\gamma\dd(t) = \nabla u(x,y)</m>. Typically, the problem of computing flows lines explicitly is hard. However, for certain functions <m>u</m>, this problem turns out to be much easier.</p>

            <p>In particular, if <m>u</m> is harmonic, the associated gradient field has some very nice features. First, since <m>u</m> is <m>C^2</m>, it isn't hard to calculate that the curl of <m>\operatorname{grad} u</m> is zero. (One can do this by extending <m>\gd u</m> to a function in <m>\R^3</m> by putting 0 in the <m>z</m> coordinate, computing <m>\nabla \times \nabla u</m>, and applying Clairaut's theorem.)</p>

            <p>Second, computing the divergence of <m>u</m>, we get
            <me>
                \operatorname{div} \gd u = \nabla \cdot \nabla u = 0,
            </me>
            and so <m>u</m> is also divergence free.</p>

            <p>Because the gradient field arising from a harmonic is function is so nice, we get a magical solution to the flow line problem.</p>

            <theorem xml:id="theorem-flow-lines-for-harmonic-functions">
                <title>Flow lines for harmonic functions</title>
                <statement>Suppose that <m>u</m> is harmonic on a domain <m>A</m>. If <m>u = C</m> are lines of constant value for <m>u</m> (so-called level curves), then the level curves of the harmonic conjugate <m>u\ad</m> are the flow lines of <m>u</m>.</statement>
            </theorem>

            <p>Since a harmonic function <m>u</m> and its harmonic conjugate <m>u\ad</m> form the real and imaginary parts of analytic functions, we see immediately the connection to ideas from complex analysis. Indeed, the function
            <me>
                f(z) = u(x,y) + i u\ad(x,y)
            </me>
            is called a <term>complex potential</term> function.</p>

            <p>We now consider the problem of finding a harmonic function on a domain that agrees with some sort of given boundary conditions. Recall that a <term>harmonic</term> function <m>u</m> on a domain <m>A \subset \R^2</m> is a <m>C^2</m> function that satisfies <term>Laplace's equation</term>; that is, <m>u</m> is harmonic on <m>A</m> if
            <me>
                \nabla^2 u = \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = 0.
            </me></p>

            <p> Boundary value problems associated with harmonic functions come with two varieties of standard conditions. 
                <ol>
                    <li>Dirichlet problem: we specify the <em>values</em> of <m>u</m> at the boundary of <m>A</m>.</li>
                    <li>Neumann problem: we specify the derviative of <m>u</m> at the boundary of <m>A</m>, in the sense that we specify 
                    <me>
                        \frac{\partial u}{\partial n} = \operatorname{grad} u \cdot n.
                    </me></li>
                </ol>
            </p>
        </subsection>
        <subsection>
                <title>The Dirichlet problem on the disk</title>
            <p>It turns out that there is a very nice solution to the Dirichlet problem in the case that the domain <m>A</m> is a disk. A famous result called the Poisson integral theorem gives us the desried solution. Harmonic functions have a mean value property much like Gauss's mean value theorem for analytic functions. We'll restrict our attention to the case of the unit disk (which implies the result for any other disk).</p>

            <theorem xml:id="theorem-mean-value">
                <title>Harmonic mean value property</title>
                <statement>Suppose that <m>u</m> is harmonic in a neighborhood of the unit disk. Then
                <me>
                    u(0) = \frac{1}{2pi} \int_0^{2\pi} u(e^{i\theta}) \, d\theta.
                </me></statement>
            </theorem>

            <p>Poisson's formula extends the mean value property to give the value of <m>u</m> at <em>every</em> point in the disk in terms of the values of <m>u</m> on the boundary.</p>

            <theorem xml:id="theorem-poisson-integral-formula">
                <title>
                    Poisson integral formula
                </title>
                <statement>Assume that <m>u</m> is harmonic on a neighborhood of the unit disk. Then for any <m>z \in \D</m>, 
                <me>
                    u(z) = \frac{1}{2\pi} \int_0^{2 \pi} u(e^{i\theta}) \frac{1- \abs{z}^2}{\abs{e^{i\theta} - z}^2}\,d\theta.
                </me></statement>
            </theorem>

            <p>The proof of the theorem above goes essentially by applying the conformal automorphism of <m>\D</m> that takes <m>z \to 0</m>. Then, we apply the harmonic mean value property and chase through the effect on the integral of the conformal map.</p>

            <p>The solution to the Dirichlet problem is basically a converse to Poisson's formula - it asserts that given a function <m>u_0</m> continuous on the unit circle <m>T</m>, we can construct a unique harmonic function <m>u</m> on <m>\D</m> that agrees with <m>u_0</m> on the boundary. </p>

            <theorem xml:id="theorem-solution-to-dirichlet-problem-on-the-disk">
                <title>Solution to Dirichlet problem on the disk</title>
                <statement>Let <m>u_0</m> be a continuous function  on <m>\T</m>. Then there exists a unique harmonic function <m>u</m> on <m>\D</m> that extends continuously to <m>u_0</m> on <m>\T</m>. The formula for <m>u</m> with <m>z \in \D</m> is
                <me>
                    u(z) = \frac{1}{2\pi} \int_0^{2\pi} u_0(e^{i\theta}) \frac{1 - \abs{z}^2}{\abs{e^{i\theta} - z}^2} \, d\theta.
                </me></statement>
            </theorem>

        </subsection>

        <subsection>
            <title>Neumann conditions</title>
            <p>Note that while we have a standard solution to the Dirichlet problem on the disk for any continuous function <m>u</m> on the circle bounding the disk, we have much stricter requirements for our choice of <m>u</m> in the Neumann case.</p>

            <p>Suppose that we have a harmonic function <m>u</m> on <m>A</m> that extends to a differentiable function at the boundary <m>\partial A</m> (we may as well assume that the boundary is a simple closed and piecewise continuous, parametrized by the curve <m>\gamma</m>). Let <m>\phi</m> denote the derivative <m>\phi = \frac{\partial u}{\partial n}</m> where <m>n</m> is the normal vector to the boundary. Then by the divergence formulation of Green's theorem, we get
            <md>
                <mrow>\int_\gamma \frac{\partial u}{\partial n} \, ds \amp= \int_\gamma (\gd u)\cdot n \, ds</mrow>
                <mrow>\amp= \int_A \operatorname{div}\gd u\, dxdy</mrow>
                <mrow>\amp= \int_A \nabla^2 u \, dx dy</mrow>
                <mrow>\amp= 0.</mrow>
            </md></p>

            <p>Thus we consider boundary functions <m>\phi</m> with <m>\int_\gamma \phi = 0.</m> In the context of these notes, we actually will restrict ourselves to the simplest case, <m>\partial u/\partial n = 0</m>, which corresponds to zero-flux across the boundary, a condition known as an <term>insulated</term> boundary. This means that flows will be parallel the the boundary in this case (which corresponds to the simple case of uniform fluid flow, e.g.).</p>

        </subsection>
        <subsection>
            <title>Standard solutions and conformal maps</title>
            <p>Our essential approach will be to construct a standard solution that describes some physical situation and then conformally map it to more interesting regions, which will also transform the solution.</p>

            <p>As a first standard solution, consider the case of a fluid that is incompressible and nonviscous. If we also assume that the flow is given by an integrable vector field <m>V</m> so that <m>\gd V = u</m> for a potential function <m>\phi</m>, then we have that <m>\phi</m> is harmonic. The conjugate <m>\psi</m> of <m>\phi</m> is called a stream function. Consider the vector field <m>V</m> given by
            <me>
                V(x,y) = (\alpha, 0).
            </me>
            <figure>
                <image source="unifstream.jpg"/>
                <caption>Uniform flow, velocity <m>\alpha</m></caption>
            </figure></p>
            
            <p>The vector field <m>V</m> is the gradient of the potential function <m>\phi = \alpha x</m>, which in turn is the real part of the complex function <m>f(z) = \alpha z</m>. Since <m>\phi</m> is the real part of an analytic function, it is harmonic. Further, as the flow is parallel to the boundary, the Neumann condition <m>\partial \phi/\partial n = 0 </m> is met.</p>

            <p>A map that first arose in the early study of airfoils is the <url href="https://en.wikipedia.org/wiki/Joukowsky_transform">Joukowsky transform</url>, defined by <me>T(z) = z + \frac{1}{z}</me>. An exercise will ask you to look at this map more closely. For the purposes of our example, this map transforms the upper half plane with half of a unit disk removed conformally to the upper half plane.</p>

            <figure>
                <sidebyside>
                    <image source="cylplane.jpg"/>
                    <image source="halfplane.jpg"/>
                </sidebyside>
                <caption>Image of <m>z \mapsto z + 1/z</m></caption>
            </figure>

            <p>We'll need the following highly useful interaction between conformal maps and harmonic functions.</p>

            <proposition xml:id="proposition-harmonic-functions-">
                <statement>If <m>u</m> is a harmonic function on a domain <m>A</m> and <m>T</m> is a conformal map from a domain <m>B</m> to <m>A</m>, then <m>u \circ T</m> is harmonic on <m>B</m>.</statement>
            </proposition>

            <p>How can we blend all of these ingredients together? We've already seen that <m>\phi(x,y) = \alpha x</m> is a solution to Laplace's equation on the upper half plane satisfying the condition that <m>\partial \phi/\partial n = 0</m> on the real axis. Lifting to the complex potential <m>\Phi(z) = \alpha z</m>, we compose with the map <m>T(z) = z + 1/z</m> to get a new function <me>F(z) = \phi \circ T = \alpha(z + \frac{1}{z})</me> that is analytic on the upper half plane with the unit disk removed. The real and imaginary parts of <m>F</m> give harmonic functions that describe the equipotentials and the flow lines for the transformation of uniform flow under <m>T</m> (the geometry is preserved by conformality). The image below shows the effect on the flow lines of the transformation.</p>

            <figure>
                <sidebyside>
                    <image source="unifstream.jpg"/>
                    <image source="uniftocyl.jpg"/>
                </sidebyside>
                <caption>Stream lines under the map <m>z \to z + 1/z</m></caption>
            </figure>

            <p>An exercise will ask you to evaluate this more carefully.</p>
        </subsection>
        <subsection>
            <title>Half plane solutions</title>

            <p>In the Dirichlet setting, we already have the Poisson integral formula (which can be applied to any domain conformally equivalent to a disk). However, this is often way more than necessary, as frequently boundary conditions are specified as constant on a finite number of pieces of the boundary. In this sort of case, a standard solution is most easily defined on the upper half plane.</p>

            <p>We want to find a harmonic function <m>u</m> on the upper half plane with the boundary condition that <m>u(x,0)=1</m> when <m>x \lt 0</m> and <m>u(x,0) = 0</m> when <m>x > 0</m>.</p>

            <p>If <m>z = x + iy</m>, one such solution is the function <me>u = \frac{1}{\pi} \theta</me> where <me>\theta = \arg z = \arctan y/x.</me> Notice that
            <me>
                \frac{1}{\pi} \arg z = \RE(\frac{1}{i \pi} \log z),
            </me>
            and so <m>u</m> is harmonic.</p>

            <figure>
                <caption>Basic half plane standard solution</caption>
                <image source="standhalf.jpg"/>
            </figure>

            <p>With a bit of shifting, we can construct a superposition of solutions that describes the more general case of a finite number of intervals on the real axis, each assigned a constant initial value. For example, consider the boundary problem in the figure below. We have four regions, separated by the points <m>x = a, b, c</m>, and initial temperatures on the induced intervals given by <m>c_0, c_1, c_2, c_3</m>. Now take the angles from the points <m>a, b, c</m> to <m>z = x+iy</m>. Then the standard upper half plane solution in this case is 
            <me>
                u = c_3 + \frac{c_2 - c_3}{\pi} \theta_3 + \frac{c_1 - c_2}{\pi} \theta_2 + \frac{c_0 - c_1}{\pi}\theta_1.
            </me> </p>

            <p>A bit of translating will get you the complex potential
                <me>
                    f(z) = c_3 +  \frac{c_2 - c_3}{\pi i} \log(z - c) + \frac{c_1 - c_2}{\pi i} \log(z - b) + \frac{c_0 - c_1}{\pi i} \log(z - a),
                </me>
            for which <m>u = \RE f</m> (after an appropriate choice of branch). That the boundary conditions match is left to the reader. Note that this construction can be made to handle an arbitrary finite partition of the real axis into sections of constant value.</p>

            <figure>
                <caption>General half plane standard solution</caption>
                <image source="morehalf.jpg"/>
            </figure>

            <p>Finally, we'll look an example application. In the study of heat, the harmonic function <m>T</m> on a domain represents temperature, and its level curves <m>Tx, y) = c</m> are called <term>isotherms</term>. The harmonic conjugate of <m>T</m>, which we can denote <m>T\ad</m> has level curves that represent the <term>flux lines</term> induced by the gradient field <m>\nabla T</m>. Our task is to find a harmonic function on the unit disk with the left half circle on the boundary held at temperature <m>T = 0</m> and the right circle held at <m>T = 1</m>.</p>

            <p>First, we'll translate the boundary conditions to the upper half plane using the usual conformal map <me>z \mapsto w = C(z) = i \frac{1+z}{1-z}.</me> In the halfplane, we can find a function <m>\phi(w)</m> fitting the standand half plane solution by
            <me>
                \phi = 1 + \frac{0 - 1}{\pi } \theta_1 + \frac{1 - 0}{\pi} \theta_2
            </me>
            which has complex potential
            <me>
                \Phi = 1 + \frac{0 - 1}{\pi i} \log(w+1) + \frac{1 - 0}{\pi i} \log(w -1).
            </me></p>

            <p>One approach to constructing a solution on the disk is to precompose <m>\Phi</m> with the conformal map taking the disk to the upper half plane; that is, let <m>f</m> be the complex function on the unit disk given by
            <me>
                f = \Phi \circ C = 1 + \frac{ - 1}{\pi i} \log(i \frac{1+z}{1-z}+1) + \frac{1}{\pi i} \log(i \frac{1+z}{1-z} -1).
            </me></p>
            <figure>
                <caption>Using a standard solution to solve a disk problem</caption>
                <image source="diskhalf.jpg"/>
            </figure>

            <p>Now, we can look at the level curves of <m>\RE f</m> and <m>\IM f</m> to detect the isotherms and flux lines for our function on the disk. The flux lines in the plane and disk setting are visualized in the figure below.</p>

            <figure>
                <caption>Flux lines for standard half plane and disk solutions</caption>
                <sidebyside>
                    <image source="tempexampleplane.jpg"/>
                    <image source="tempexampledisk.jpg"/>
                </sidebyside>
            </figure>


        </subsection>
    </section>

    <section>
        <title>Exercises 3</title>
        <exercises>
            <exercise>
                <p>Compute the image of the triangle with corners <m>z = 0, z = 1/2, z = 1/2 + 1/2 i</m> under inversion across the unit circle. Where does the interior go? Are the angles between the sides preserved in the image?</p> 
            </exercise>
            <exercise>
                <p>Show that a linear fractional transform can have at most two points so that <m>T(z) = z</m>. Write an example of a LFT with <m>T(\infty) = \infty</m>.</p>
            </exercise>
            <exercise>
                <p>Show that the map <me>z \mapsto z + \frac{1}{z}</me> takes the unit circle to the segment <m>[-2, 2] \subset \R</m>. Where is this map conformal?</p>
            </exercise>
            <exercise>
                <p>Compute the real and imaginary parts of the composition of a uniform flow on the upper half plane with the map <m>z \mapsto z + 1/z</m>. Use your favorite visualizer to confirm that the level curves for these functions are orthogonal. You might also consider adding an image of the unit circle to your plot. (I used desmos for this).</p>
            </exercise>
            <exercise>
                <p>Prove that the map given by <m>u(x, y) = \frac{1}{\pi} \theta</m> is harmonic on the upper half plane, where <m>\theta = \arg (x + iy)</m>. Show that this function has boundary values of <m>u(x, 0) = 1</m> for <m>x \lt 0</m> and <m>u(x,0) = 0</m> for <m>x > 0</m>.</p>
            </exercise>
            <exercise>
                <p>Use the solution above to find a harmonic solution <m>u</m> to the Dirichlet problem on the disk where <m>u = 0</m> on the upper half of the unit circle, and <m>u = 1</m> on the lower half of the unit circle. Hint: consider the conformal map <me>T = i \frac{1+ z}{1-z}.</me></p>
            </exercise>
            <exercise>
                <p>Find the image of the upper half of the unit disk under the map <me>z \mapsto \operatorname{Log} z.</me> (That is, it isn't enough to know what the answer is, you need to show it!) Is this map conformal? What is the inverse map?</p>
            </exercise>
            <exercise>
                <p>Determine the image of the map <m>z \mapsto \sin z</m> on the half-strip with boundary <m>y = 0, x = 0, x = \pi/2</m> with <m>0 \leq x \leq \pi/2</m> and <m>y > 0</m> (your image should be a quarter-plane: make sure to track where the boundary pieces map). Use this conformal map to find a harmonic function giving the temperature on the first quadrant, with boundary conditions <m>T = 1</m> on the positive imaginary axis, <m>T</m> is insulated on the interval <m>0 \leq x \leq 1</m>, and <m>T = 0</m> on the rest of the real axis. (Bonus, use a visualizer to draw the flow lines by finding the level curves of the harmonic conjugate of <m>T</m>.)</p>
            </exercise>

        </exercises>
    </section>

    </chapter>

    <chapter>
        <title>Special functions and analytic continuation</title>
        <section>
            <title>The Gamma Function</title>
            <subsection>
                <title>Interpolation</title>
                <p>An <term>interpolation</term> problem is one where we are given input data <m>z_1, \ldots, z_n</m> and output data <m>w_1, \ldots, w_n</m>, and we are asked to find an <term>interpolating function</term> <m>f</m> subject to some kind of conditions (e.g. continuity, bounded, differentiable, etc) so that 
                <me>
                    f(z_i) = w_i \text{ for all } i=1, \ldots n.
                </me></p>

                <p>As an example, consider the problem of constructing a polynomial that interpolates the points <m>(z_1, w_1), (z_2, w_2), (z_3, w_3) \in \R^2</m>. If these points arent collinear, one approach to solving the problem is to use elbow grease - we can write a generic parabola <m>f(z) = az^2 + bz + c</m> and solve the system of three equations that arise from plugging in each of the points. Another approach, based on noticing patterns, is called <em>Lagrange interpolation</em>. We notice that 
                <me>
                    f_1(z) = \frac{(z - z_2)(z-z_3)}{(z_1 - z_2)(z_1 - z_3)}
                </me>
                is a function so that <m>f_1(z_2) = f_1(z_3) = 0</m> and that <m>f_1(z_1) = 1</m>. We can construct similar functions <m>f_2</m> and <m>f_3</m>. Then we can assemble these into a interpolating function by multiplying the correct piece by the desired output value -
                <me>
                    f(z) = w_1 f_1(z) + w_2 f_2(z) + w_3 f_3(z).
                </me>
                It turns out that the Lagrange interpolating function will be the unique polynomial of lowest degree that interpolates the data.</p>

                <p>Of course, we can construct more exotic interpolation problems. We're going to begin with a problem where we wish to interpolate an infinite number of data points.</p>
            </subsection>
            <subsection>
                <title>The Gamma Function</title>
                <p>We wish to construct a function so that <m>f(n) = n!</m> - that is, we want a function that interpolates the factorial function. (One way of thinking about the objective is to give an expression like <m>(1/2)!</m> meaning, as formulas involving factorials can often be extended to take non-integer values). We'll want our function to be continuous and to be defined on the largest domain we can construct.</p>

                <p>Mathematicians of the 18th century, in the course of working out the basics of the theory of integral transforms, noticed that something special happened to the integral
                    <me>
                        \int_0^\infty f(t) e^{-t}\, dt
                    </me>
                when <m>f(t) = t^n</m>.
                <aside>
                    <p>The astute reader may notice that this is very similar to the Laplace transform <m>\mathcal{L}{f} = \int_0^\infty f(t) e^{-st} \, dt</m>.</p>
                </aside></p>

                <p>Following Bernoulli (and Legendre), make the following definition involving our interesting integral.
                    <me>
                        \Gamma(n) = \int_0^\infty t^{n-1} e^{it} \, dt.
                    </me>
                Using integration by parts, we can derive
                <md>
                    <mrow>\Gamma(n) \amp= \int_0^\infty t^{n-1} e^{it} \, dt</mrow>
                    <mrow>\amp= -t^{n-1}e^{it}\bigg\vert_0^\infty + \int_0^\infty(n-1)t^{n-2}e^{-t}\, dt</mrow>
                    <mrow>\amp= (n-1) \int_0^\infty t^{n-2} e^{-t}\, dt</mrow>
                    <mrow>\amp= (n-1)\Gamma(n-1).</mrow>
                </md>
                Coupled with the observation that <m>\Gamma(1) = 1</m>, we get that
                <me>
                    \Gamma(n+1) = n!.
                </me>
                Now, the nice thing about the form of the integral in the definition of <m>\Gamma</m> is that we can apply it to any <m>x \gt 0</m>, and in turn <m>\{z: \RE z \gt 0\}</m> and get a convergent integral. Thus, the form of the gamma function allows the <em>continuation</em> of the function off of the positive integers and onto the entire right half plane.</p>

                <p>The equation 
                    <me>
                        \Gamma(z+1) = z \Gamma(z)
                    </me>
                is an example of a <em>functional equation</em> (or an equation where the unknowns are functions), and it turns out that we can use this equation to extend the domain of the gamma function beyond the right half plane.</p>

                <p>Suppose that we are given a point <m>z_0</m> with <m>0 > \RE z_0 > -1</m>. The integral that defines <m>\Gamma</m> on the right half plane isn't convergent on this value. It is reasonable to expect that if <m>\Gamma(z_0)</m> is to be made meaningful, then the functional equation should hold. That is, we desire
                <me>
                    z_0 \Gamma(z_0) = \Gamma(z_0 + 1).
                </me>
                Accordingly, we can <em>define</em> <m>\Gamma</m> at <m>z_0</m> via
                <me>
                    \Gamma(z_0) := \frac{\Gamma(z_0 +1)}{z_0}.
                </me>
                Notice that this definition works for any <m>z</m> with <m>\RE z > -1</m> with the exception of the point <m>z = 0</m>, which is a pole of our extension. Thus, we've extended the domain of <m>\Gamma</m> to the strip <m>-1 \lt \RE z \leq 0</m> with the exception of the pole at <m>z = 0</m>. Proceeding inductively, we can continue to define further strips in terms of the previous using the functional equation. The resulting function is the unique meromorphic function defined this way on all of <m>\C - \{0, -1, -2, -3, \ldots\}</m>.</p>

            </subsection>
        </section>
        <section>
            <title>Analytic continuation</title>

        </section>
    </chapter>

    <chapter>
        <title>The prime number theorem</title>
        <section>
            <title>Prerequisites</title>
            <subsection><title>Complex analysis</title>
            <p>Let us begin with a very useful sort-of converse to the Cauchy-Goursat theorem</p>

            <theorem xml:id="thm-cauchy-goursat">
                <title>Cauchy-Goursat</title>
                <p>Let <m>f</m> be analytic on a simply connected domain <m>D</m>. Then
                <me>
                    \oint_\gamma f \, dz = 0
                </me>
                for any simple closed curve <m>\gamma</m> contained in <m>D</m>.
                </p>
            </theorem>


            <theorem xml:id="thm-morera"><title>Morera's theorem</title>
                <p>Let <m>f</m> be a continuous function defined on an open domain <m>D</m>. If
                <me>
                    \oint_\gamma f(\xi) \, d\xi = 0
                </me>
                for every simple closed path <m>\gamma</m> contained in <m>D</m>, then <m>f</m> is analytic on <m>D</m>.
                </p>
            </theorem>

            <proof>
                <p>Assume without loss of generality that the domain <m>D</m> is connected (and so path-connected). Assume that <m>f</m> satisifies the hypotheses of the theorem. We will construct an anti-derivative for <m>f</m>, which will allow us to conclude that <m>f</m> is analytic.</p>

                <p>Pick a basepoint <m>z_0</m> in <m>D</m>, and for any other <m>z</m> in <m>D</m>, let <m>\gamma</m> be a simple path from <m>z_0</m> to <m>z</m>. Let <m>F</m> be the function on <m>D</m> given by
                <me>
                    F(z) = \int_\gamma f(\xi) \, d\xi.
                </me></p>

                <p>Note that this definition does not depend on the choice of path. Assume that <m>\tau</m> is another path from <m>z_0</m> to <m>z</m>. Then, by hypothesis,
                <md>
                    <mrow> 0 \amp= \oint_{\tau\inv \gamma} f</mrow>
                    <mrow>\amp = \oint_{\tau\inv} f + \oint_\gamma f</mrow>
                    <mrow>\amp = -\oint_{\tau} f + \oint_\gamma f</mrow>
                </md>
                which implies that <m>\oint_\tau f = \oint_\gamma f</m>.</p>

                <p>Note futher that a different choice of basepoint (say <m>z_1</m>) causes the resulting function to differ from <m>F</m> only by the constant <m>C = \oint_C f</m> where <m>C</m> is any simple path from <m>z_1</m> to <m>z_0</m>. Thus, choice of basepoint does not affect the derivative.</p>

                <p>It remains to show that <m>\frac{d}{dz} F(z) = f(z)</m>. This boils down to a difference quotient argument. Consider <m>F(z + h)</m> for some small complex number <m>h</m>. Then
                <me>
                    F(z+h) - F(z) = \int_{z_0}^{z+h} f(\xi) \, d\xi - \int_{z_0}^z f(\xi) \, d\xi = \int_z^{z+h} f(\xi) \, d\xi.
                </me>
                (The notation is justified by the path independence of integrals of <m>f</m>.)  Now,
                <md>
                    <mrow>\frac{1}{h} (F(z + h) - F(z)) - f(z) \amp= \frac{1}{h} (F(z + h) - F(z)) - \frac{1}{h} hf(z) </mrow>
                    <mrow> \amp = \frac{1}{h} (\int_z^{z + h} f(\xi) \, d\xi - h f(z))</mrow>
                    <mrow> \amp = \frac{1}{h} (\int_z^{z + h} f(\xi) \, d\xi - \int_z^{z+h} f(z) \, d\xi)</mrow>
                    <mrow>\amp= \frac{1}{h} \int_z^{z+h} f(\xi) - f(z) \, d\xi.</mrow>
                </md> 
                Since <m>f</m> has path independent line integrals, choose the line segment between <m>z</m> and <m>z + h</m>. Since <m>f</m> is continuous, 
                <me>
                    \abs{\frac{F(z + h) - F(z)}{h} - f(z)} \leq \frac{1}{h} \int_z^{z+h} \abs{f(\xi) - f(z)} \, d\xi \to 0 \text{ as } \abs{h} \to 0.
                </me></p>

                <p>We conclude that <m>F</m> is differentiable at <m>z</m> and thus analytic at <m>z</m> with derivative <m>f</m>, which implies that <m>f</m> is analytic. Since this holds for all <m>z\in D</m>, we conclude that <m>f</m> is analytic on <m>D</m>.</p>

            </proof>

            <p>Morera's theorem is often used with weaker (equivalent) hypotheses - that is, we need only check that
                <me>
                    \int_{\partial T} f\, dz = 0
                </me>
                around the boundary of any closed triangle <m>T</m> contained in <m>D</m>.</p>

            <p>Morera's theorem is the standard method used to prove that a constructed function is holomorphic. The theorem is used so often and so widely that it may sometimes be invoked without reference (though not in our case).</p>

            <p>One nice immediate result that we get from Morera is parallel to the (fundamental) result from real analysis that uniform limits of continuous functions are continuous.</p>

            <theorem xml:id="thm-unif-holo">
                <p>The uniform limit of a sequence of analytic functions is analytic.</p>
            </theorem>

            <proof>
                <p>Suppose that a sequence <m>f_n</m> of analytic functions converges uniformly to a continuous limit function <m>f</m> on an open disk. The Cauchy-Goursat theorem implies that, for all <m>n</m>, 
                <me>
                    \oint_C f_n \, dz = 0
                </me>
                for any simple closed curve <m>C</m> contained in the disk. Using uniform converge to push the limit through the integral, we get
                <me> 
                    \oint_C f \, dz = \oint_C \lim_n f_n \, dz = \lim_n \oint_C f_n \, dz = 0.
                </me>
                for every simple closed curve <m>C</m> in the disk, and so by Morera's theorem, <m>f</m> must be analytic on the disk.</p>

                <p>This result extends to domains, as we can recreate this argument in a neighborhood of any <m>z_0</m> in <m>D</m>.</p>
            </proof>

            <p>Since we'll be considering functions defined as series, it will be useful to combine the results above with a test for uniform convergence called the Weierstrass M-test.</p>

            <theorem xml:id="thm-M-test"><title>M-test</title>
            <p>Supposet that <m>\{f_n\}</m> is a sequence of functions on a common domain <m>D</m> and that there exists a sequence of non-negative numbers <m>\{M_n\}</m> satisfying
            <ol>
                <li><m>\abs{f_n(z)} \lt M_n</m> for all <m>n \in \N</m>;</li>
                <li> <m>\displaystyle \sum_{n=1}^\infty M_n \lt \infty</m>.</li>
            </ol>
            Then <m>\sum_{n=1}^\infty f_n</m> converges absolutely and uniformly on <m>D</m>.</p>
            </theorem>out 
        </subsection>
        <subsection><title>Measure theory</title>
            <p>To be rigorous about convergence, we're going to need some extremely useful tools from analysis. The discussion here will mostly bracket out proofs, which are typically done in a graduate course in real analysis.</p>

            <p>A <term>measure</term> is a function that assigns a numerical value to a set. The idea comes from an effort to generalize the notion of the length of an interval. A brief overview of the setup follows. We have a set <m>X</m> (for example, <m>X=\R</m>), and we want to define a function <m>\mu: A \subset X \to [0,\infty]</m> (note the inclusion of <m>\infty</m>). It turns out that we can't measure every subset of <m>X</m> (that darn axiom of choice). So we equip <m>X</m> with a sort of topology called a <m>\sigma</m>-algebra consisting of so called measurable sets. </p>

            <definition>
                <p>Given a set <m>X</m>, a <m>\sigma</m>-algebra on <m>X</m> is a non-empty collection <m>\Sigma</m> of subsets of <m>X</m> that is closed under complements, countable unions, and countable intersections.</p>
            </definition>

            <definition> 
                <p>Let <m>X</m> be a set and <m>\Sigma</m> a <m>\sigma</m>-algebra on <m>X</m>. A set function <m>\mu:\Sigma \to [0,\infty]</m> is a measure if
                <ul>
                    <li>For all <m>E \in \Sigma</m>, <m>\mu(E) \geq 0</m>.</li>
                    <li><m>\mu(\emptyset) = 0</m>.</li>
                    <li>For all countable collections <m>\{E_j\} \subset \Sigma</m> of pairwise disjoint sets, <me>\mu(\bigcup_j E_j) = \sum_j \mu(E_j).</me></li>
                </ul></p>
            </definition>

            <p>One important example of a measure is <term>Lebesgue measure</term>, which directly generalizes the length of intervals. Lebesgue measure is usually defined on the Borel sets <m>\mathcal B</m>, which is the <m>\sigma</m>-algebra constructed by starting with the open intervals in <m>\R</m> and combining them in all ways to ensure that the conditions for a <m>\sigma</m>-algebra are met. Measures can be far stranger than Lebesgue measure. The Dirac measure at <m>x_0</m>, also called a point mass, is a measure that assigns a value of 1 to any set <m>E</m> containing <m>x_0</m> and <m>0</m> otherwise. </p>

            <p>To work with measures, we'll also need a family of compatible functions.</p>

            <definition>
                <p>Suppose that <m>X</m> is a set and <m>\Sigma</m> is a <m>\sigma</m>-algebra on <m>X</m>. A function <m>f: X \to \R</m> is measurable if 
                <me>
                    f\inv(B) \in \Sigma
                </me>
                for every Borel set <m>B \in \mathcal B</m>.</p>
            </definition>

            <p>Measures allow a powerful generalization of integrals, replacing the familiar <q><m>dx</m></q>, which can be thought of as the length of a small interval, with <m>d\mu</m>. The essential approach is to approximate a function from below by step functions, which is called <term>Lebesgue integration</term>. That is, given a set <m>X</m>, a <m>\sigma</m>-algebra <m>\Sigma</m>, a measure <m>\mu</m> (together called a <term>measure space</term> (X, <m>\Sigma, \mu)</m>) and a function <m>f:X \to [0,\infty]</m>, any partition of <m>X</m> by subsets <m>A_i</m> of <m>\Sigma</m> leads to the integral-ish sum
            <me>
                \sum_{i=1}^m \mu(A_i) \inf_{A_i} f.
            </me>
            You can view this as in the spirit of a Riemann sum - we're cutting <m>X</m> up into pieces (but that need not be intervals) and under-estimating <m>f</m> on those pieces. While this isn't strictly the area of a rectangle as in the Riemann case (as the <m>A_i</m> can be very non-interval), the idea is similar.</p>

            <definition>
            <p>When such a sum has a supremum over all <m>\Sigma</m>-partitions of <m>X</m>, we can define the <term>integral of f with respect to <m>\mu</m></term> by
            <me>
                \int f \, d\mu = \sup \{\sum_{i=1}^m \mu(A_i) \inf_{A_j} f: A_1, \ldots A_m \text{ is a } \Sigma-\text{partition of } X\}.
            </me></p>
            </definition>

            <p>Lebesgue measure gives rise to integrals that directly generalize the Riemann integral - that is, if a function is Riemann integrable, then it is Lebesgue integrable and the integrals agree. (Note: unlike some authors, I do not admit improper Riemann integrals into the class of Riemann integrable functions.)</p>

            <p>A more interesting example is to consider the Dirac measure <m>\delta_a</m> where <m>a \in X</m>. That is, <m>\delta_a(E) = 1</m> if <m>a \in E</m> and <m>0</m> otherwise. Notice that for any partition of <m>X</m>, <m>a \in A_i</m> for exactly one <m>k</m>. So 
            <me>
                 \sum_{i=1}^m \delta_a(A_i) \inf_{A_i} f = 1 \inf_{A_k} f
             </me>
             and that the sup of these sums will be <m>f(a)</m>!.
             That is,
             <me>
                \int_X f \, d\delta_a = f(a).
            </me>
            </p>

            <p>All this new machinery isn't much good if we don't get beefy new tools to work with. One of the big problems that Lebesgue integration is meant to solve is the failure in Riemann integration of being able to push limits inside integrals. In the Lebesgue setting, we have very powerful theorems describing when this can be done.</p>

            <p>A sequence of functions <m>f_k:X \to [0,\infty]</m> is called <term>increasing</term> if for each <m>x \in X</m>, we have <m>f_1(x) \leq f_2(x) \leq \ldots</m>.</p>

            <theorem xml:id="thm-mct"><title>Monotone convergence theorem</title>
            <p>Suppose that <m>(X, \Sigma, \mu)</m> is a measure space and that <m>0 \leq f_1 \leq f_2 \leq \ldots</m> is an increasing sequence of measurable functions. Define <m>f: X \to [0,\infty]</m> by 
            <me>
                f(x) = \lim_{k \to \infty} f_k(x).
            </me>
            Then
            <me>
                \lim_{k \to \infty} \int f_k \, d\mu = \int f \, d\mu.
            </me></p>
            </theorem>

            <p>An even beefier theorem states that we can push limits into integrals when the sequence of functions is dominated by a function with bounded integral. Note: I'm not covering the leap to complex measures here, but one can imagine that a real-valued measure is a sum of two positive measures, and that a complex measure is a sum of real measures in the obvious way.</p>

            <theorem><title>Dominated convergence theorem</title>
            <p>Suppose that <m>(X, \Sigma, \mu)</m> is a measure space and that <m>f_n</m> is a sequence of complex-valued measurable functions. Suppose that <m>f_n</m> converges pointwise to <m>f</m> and that there exists a measurable function <m>g</m> such that 
            <me>
                \abs{f_n(x)} \leq g(x)
            </me>
            for all <m>x\in X</m> and all <m>n</m> and
            <me>
                \int g \, d\mu \lt \infty.
            </me> 
            Then <m>f</m> is integrable and
            <me>
                \lim_{n\to \infty} \int f_n \, d\mu = \int f \, d\mu.
            </me>
                </p>
            </theorem>


        </subsection>

        </section>

        <section>
            <title>Infinite products and the zeta function</title>

            <subsection><title>The zeta function</title>

            <definition xml:id="def-zeta"><title>Riemann zeta function</title>
                <p>Let <m>s</m> be a real number. Define the <term>Riemann zeta function</term> by
                <me>
                    \zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}.
                </me></p>
            </definition>

            <p>This is essentially taking the <q><m>p</m>-series</q> from calculus and turning it into a function using the power as a parameter. It isn't hard to see that this function will converge for real <m>s > 1</m> via the integral test (exercise).</p>

            <theorem xml:id="thm-zeta-holo">
                <p><m>\zeta</m> is holomorphic for <m>\RE s > 1</m>.</p>
            </theorem> 

            <proof>
                <p>First, note that for a positive real number <m>n</m> and a complex power <m>s = a + ib</m>, note that
                <md>
                    <mrow> \abs{n^{s}} \amp= \abs{n^{a+ib}}</mrow>
                    <mrow> \amp= n^a \abs{n^{ib}}</mrow>
                    <mrow> \amp = n^{\RE s}</mrow>
                </md></p>

                <p>For <m>\eps \gt 0</m>, let <m>s</m> be a complex number with <m>\RE s > 1+\ep</m>. Consider the sequence of functions
                <me>
                    f_n = \frac{1}{n^s}.
                </me>
                We have
                <ol>
                    <li>
                        <me>
                            \abs{f_n(s)} = \abs{\frac{1}{n^s}} = \frac{1}{n^{\RE s}} \leq \frac{1}{n^{1 + \eps}} =: M_n.
                        </me></li>
                    <li>
                        <me>
                            \sum_{n=1}^\infty M_n = \sum_{n=1}^\infty \frac{1}{n^{1+\eps}} \lt \infty.
                        </me></li>
                </ol>
                By the Weierstrass <m>M</m>-test <xref ref="thm-M-test"/>, the series converges  uniformly and absolutely to <m>\zeta</m> where <m>\RE s > 1 + \eps</m>.</p>

                <p>Now note that each <m>f_n = \frac{1}{n^s}</m> is analytic, and so each partial sum
                <me>
                    F_k = \sum_{n=1}^k \frac{1}{n^s}
                </me>
                is analytic. So <m>F_k</m> is a sequence of analytic functions converging uniformly to <m>\zeta</m> on <m>\RE s > 1 + \ep</m>. Then by <xref ref="thm-unif-holo"/>, we conclude that <m>\zeta</m> is analytic on <m>\RE s > 1+\ep</m>. Because <m>\ep</m> was arbitrary, the results extend to all points in the halfplane <m>\RE s > 1</m>.</p>
            </proof>

            <p>In fact, we can say slightly more almost immediately. First, let's codify the result that we used in the proof of the theorem above.</p>

            <theorem><title>Weierstrass theorem for series</title>
                <p>Let <m>f_n</m> be a sequence of holomorphic functions on a domain <m>D</m>, and assume that <m>\sum_n f_n</m> converges uniformly on every closed and bounded subset of <m>D</m>.  Then
                <ol>
                    <li><m>f = \sum_n f_n</m> is holomorphic on <m>D</m>.</li>
                    <li>For any <m>k \geq 1</m>, the series of <m>k</m>th derivatives <m>\sum_n f_n^{(k)}</m> converges on <m>D</m> and converges uniformly and absolutely on every closed and bounded subset of <m>D</m> to the function <m>f^{(k)}</m>. That is, the derivative of the limit is the limit of the derivatives.</li>
                </ol></p>
            </theorem>

            <corollary><title>Corollary to <xref ref="thm-zeta-holo"/></title>
                <p>For <m>\RE s > 1</m>, 
                    <me>
                        \frac{d}{ds} \zeta(s) = -\sum_{n=1}^\infty \frac{\log n}{n^s}
                    </me>
                and <m>\zeta\dd(s)</m> is holomorphic.</p>
            </corollary>

            <p>The first thing we might like to do is ask if we know the value of <m>\zeta</m> for any input points at all. The famous problem identified with the case where <m>s=2</m> is called the <term>Basel problem</term>. Its solution will showcase some of the issues we face when dealing with the task of extending the zeta function off the natural domain.</p>

            <theorem><title>Basel problem</title>
                <p>
                    <me>
                    \zeta(2) = \frac{\pi^2}{6}.
                    </me>
                </p>
            </theorem>

            <p>First, we'll show Euler's (ingenious but rather iffy) argument to highlight points where we need to drive deeper. To begin, Euler knew that
                <me> 
                    \sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \ldots,
                </me>
                and so 
                <me>
                    \frac{\sin x}{x} = 1 - \frac{x^2}{3!} + \frac{x^4}{5!} - \ldots.
                </me>
            He wants to factor this <q>polynomial</q> using the fundamental theorem of algebra as
                <me>
                    \frac{\sin x}{x} = (x - \pi)(x+\pi)(x - 2\pi)(x + 2\pi)\ldots,
                </me>
            but he can't, as this has no hope of converging in the infinite product. Instead, he defines terms of the form <m>(1 \pm \frac{x}{k\pi})</m> - after all, these terms vanish at the same set of zeros. Making the rather large leap that the function is determined by its zeros and a single value (as in the case of a polynomial), Euler writes
                <md>
                    <mrow> \frac{\sin x}{x} \amp= (1 - \frac{x}{\pi})(1 + \frac{x}{\pi})(1 - \frac{x}{2\pi})(1 + \frac{x}{2\pi})\ldots</mrow>
                    <mrow>\amp= (1 - \frac{x^2}{\pi^2})(1 - \frac{x^2}{4\pi^2})(1 - \frac{x^2}{9\pi^2})\ldots</mrow>
                </md>
            which at least has a shot of converging. He then notices that a pattern emerges as you start formally multiplying out this product.
                <me>
                    (1 - \frac{x^2}{\pi^2})(1 - \frac{x^2}{4\pi^2}) = 1 - (\frac{1}{\pi^2} + \frac{1}{2^2 \pi^2}) x^2 + O(x^4),
                </me>
                and
                <me>
                    (1 - \frac{x^2}{\pi^2})(1 - \frac{x^2}{4\pi^2})(1 - \frac{x^2}{9\pi^2}) =1 - (\frac{1}{\pi^2} + \frac{1}{2^2 \pi^2} + \frac{1}{3^2 \pi^2}) x^2 + O(x^4).
                </me>
            He makes the leap that
                <me>
                    \prod_{n=1}^\infty (1 - \frac{x^2}{k^2 \pi^2}) = 1 - (\sum_{k=1}^\infty \frac{1}{k^2 \pi^2})x^2 + O(x^4).
                </me>
            Now, still with the underlying assumption that all of this converges and makes sense, he compares the coefficients of <m>x^2</m> in his two power series to get
                <me>
                    - (\sum_{k=1}^\infty \frac{1}{k^2 \pi^2}) = \frac{-1}{3!},
                </me>
            which is just
                <me>
                    \zeta(2) = \sum_{k=1}^\infty \frac{1}{k^2} = \frac{\pi^2}{6}.
                </me></p>

            <p>This argument raises serious questions. Among them
                <ul>
                    <li>Is an analytic function determined uniquely by its zeros?</li>
                    <li>Does the fundamental theorem of algebra actually apply to infinite <q>polynomials</q>?</li>
                    <li>What does it mean to converge as an infinite product?</li>
                </ul>
            The answers to these questions will be answered in the subsequent discussion.</p>
        </subsection>

            <subsection><title>Infinite products</title>
            <p>Euler's solution to the Basel problem points out that we need to know something about convergence of infinite products. We'll start with real numbers and work up to the complex case. Given a sequence <m>a_n</m> of real numbers, we can consider the sequence of partial products <m>p_k = a_1 a_2 \ldots a_k</m>. Letting the sequence tend to infinity gives an <term>infinite product</term> (in the same way that an infinite sum is just a representation of a sequence of partial sums). The standard symbol used to denote an infinite product on the sequence <m>a_n</m> is 
            <me>
                a_1 a_2 \ldots = \prod_{n=1}^\infty a_n
            </me>.We can likewise denote the <m>k</m>th partial product by
            <me>
                p_k = a_1 a_2 \ldots a_k = \prod_{n=1}^k a_n.
            </me></p>

            <definition>
                <p>An infinite product with no zero factors is convergent if and only if there exists some real number <m>p\neq 0</m> so that <m>p_k \to p</m> as <m>k \to \infty</m>. In this case, <m>p</m> is the <term>value</term> of the product. If such <m>p_k \to 0</m>, then <m>p_k</m> diverges to 0. If there are infinitely many zero factors <m>a_n</m>, then <m>p_k</m> diverges to 0. If there are finitely many zero factors <m>a_n</m>, then <m>p_k \to 0</m>.
                </p>
            </definition>

            <p>We can construct a theory of convergence entirely in terms of products, but it is more elegant for our needs to convert questions of convergence into equivalent questions about series via the logarithm (assuming positive terms or absolute value).</p>

            <theorem> 
                <p>Let <m>a_n</m> be a sequence of positive real numbers. Then the infinite product 
                <me>\prod_{n=1}^\infty (1 + a_n)</me>
                converges if and only if the series
                <me>
                    \sum_{n=1}^\infty a_n
                </me>
                converges. </p>
            </theorem>

            <proof>
                    <p>Apply the logarithm to the product. 
                        <me>
                            \ln \prod (1 + a_n) = \sum \ln (1 + a_n).
                        </me> 
                    The series will converge if and only if the product does. Now note that
                    <me>
                        \frac{\ln(1 + x)}{x} \to 1 \text{ as } x \to 0,
                    </me>
                    (by L'Hospital or observation of the power series for <m>\ln (1 + x)</m>). If <m>a_n</m> does not tend to zero, the sum, and thus the product, will diverge by the test for divergence. So assume <m>a_n \to 0</m>. Then, as
                    <me>
                        \lim_{n \to \infty} \frac{\ln(1+a_n)}{a_n} \to 1,
                    </me>
                    the limit comparison test gives that <m>\sum \ln(1 + a_n)</m> converges if and only if <m>\sum a_n</m> converges, which establishes the claim.</p>
            </proof>

            <p>This result establishes, for example, the convergence of the <m>p</m>-series-like products <m>\prod (1 + \frac{1}{n^p})</m> where <m>p > 1</m>. That is, <em>infinite products converge when their factors tend quickly to 1</em>. </p>

            <p>How do we take this and lift it to infinite products of complex numbers? We'll follow Tao here.</p>

            <lemma><title>Absolutely convergent products</title>
            <p>Let <m>a_n</m> be a sequence of complex numbers so that <m>\sum \abs{a_n - 1} \lt \infty</m>. Then <m>\prod a_n</m> converges (absolutely). Furthermore, this product is zero if and only if one of the factors <m>a_n</m> is zero.</p>
            </lemma>

            <proof>
                <p>Because <m>\sum \abs{a_n - 1}</m> converges, the test for divergence gives <m>a_n \to 1</m>. Then there exists an <m>N</m> so that the tail of the sequence is contained in the disk <m>D(1, 1/2)</m> for <m>n > N</m>. Factor the product into 
                <me>
                    \prod_{n=1}^\infty a_n = \prod_{n=1}^N a_n \times \prod_{n = N+1}^\infty a_n.
                </me>
                Convergence of the whole product will then be equivalent to convergence of <m>\prod_{n = N+1}^\infty a_n</m>. Because the tail is away from the origin, we can apply the standard branch of the complex logarithm, <m>\Log z = \ln\abs{z} + i \Arg z</m>, on <m>D(1, 1/2)</m> and write
                <me>
                    a_n = e^{\Log a_n}.
                </me>
                Now,
                <me>
                    \Log \prod_{n=N+1}^\infty a_n = \sum_{n=N+1}^\infty \Log e^{\Log a_n} = \sum_{n=N+1}^\infty \Log a_n.
                </me>
                Similarly to the argument in the previous proof, note that the power series for <m>Log a_n</m> is <m>O(\abs{a_n-1})</m>, and so by the limit comparison test, <m>\sum_{n=N+1}^\infty \Log a_n</m> is absolutely convergent. On application of the complex exponential, we conclude that <m>\prod_{n=N+1}^\infty a_n</m> converges to <m>e^{\sum \Log a_n}</m>.</p>
            </proof>



            <p>We also have the following product form of the Weierstrass <m>M</m>-test to measure uniform convergence of products of functions.</p>

            <theorem xml:id="thm-prod-M"><title><m>M</m>-test, product form</title>
                <p>Let <m>X</m> be a set, and for all <m>n</m> let <m>f_n: X \to \C</m> be a bounded function. If for some finite <m>M</m> we have
                <me>
                    \sum_{n=1}^\infty \sup_{x \in X} \abs{f_n(x) -1} \leq M
                </me>
                then the partial products <m>\prod_{n-1}^N f_n</m> converge uniformly to <m>\prod_{n=1}^\infty f_n</m> on <m>X</m>.  </p>
            </theorem>
        </subsection>

        <subsection><title>Product formula for the zeta function</title>
            <p>We're now in position to connect the zeta function to the primes by way of the <term>Euler product formula</term>. First, let's recall the fundamental theorem of arithmetic.</p>

            <theorem><title>Fundamental theorem of arithmetic</title>
            <p>
                Every natural number <m>n \in \mathbb N</m> has a unique representation as a product
                <me>
                    n = \prod_{p} p^{a_p},
                </me>
                where the product is over the primes <m>p</m> and the exponents <m>a_p \in \mathbb N</m>, only finitely many of which are non-zero.
            </p>
            </theorem>

            <theorem><title>Product formula for <m>\zeta</m>.</title>
                <p>For <m>s \in \C</m> with <m>\RE s > 1</m>, we have
                <me>
                    \zeta(s) = \prod_{p} (1 - \frac{1}{p^s})\inv,
                </me>
                where the product is taken over the primes <m>p</m>. This representation is absolutely convergent.</p>
            </theorem>
            <proof>
                <p>For each <m>n \in \mathbb N</m>, we have
                <me>
                     n = \prod_{p} p^{a_p},
                 </me>
                 which we can formally rearrange as 
                 <me>
                    \frac{1}{n^s} = \prod_p \frac{1}{p^{a_p s}}.
                </me></p>

                <p>Now, we're going to build from the bottom. Given <m>x \geq 1, m \geq 0</m>, let <m>S_{x,m}</m> be the set of natural numbers with prime factorization containing primes no larger than <m>x</m> and exponents no greater than <m>m</m>. That is, <m>n \in S_{x,m}</m>
                has a representation
                <me>
                    n = \prod_{p\leq x} p^{a_p}
                </me>
                and <m>a_p \leq m</m>. The first observation to make is that as <m>x, m \to \infty</m>, <m>S_{x, m} \to \mathbb N</m>.</p>

                <p>The next step is a combinatorial observation. To illustrate, suppose that <m>x = 2</m> and <m>m = 2</m>. Then
                <me>
                    \sum_{n \in S_{2,2}} \frac{1}{n^s} = 1 + \frac{1}{2^s} + \frac{1}{2^{2s}}.
                </me>
                Now let <m>x = 3</m>, so that we're picking up numbers with <m>3</m> in the prime factorization. Here's where we see the pattern we're interested in show up.
                <md>
                    <mrow>\sum_{n \in S_{3, 2}} \frac{1}{n^s} \amp= 1 + \frac{1}{2^s} + \frac{1}{2^{2s}} + \frac{1}{3^s} + \frac{1}{3^{2s}} + \frac{1}{2^s 3^s} + \frac{1}{2^{2s}3^s} + \frac{1}{2^s 3^{2s}} + \frac{1}{2^{2s}3^{2s}}</mrow>
                    <mrow>\amp= (1 + \frac{1}{2^s} + \frac{1}{2^{2s}})(1 + \frac{1}{3^s} + \frac{1}{3^{2s}})</mrow>
                    <mrow>\amp= \prod_{p\leq 3} \sum_{j = 0}^2 \frac{1}{p^{js}}.</mrow>
                </md>
                If you see what's happening here, it shouldn't be hard to believe that
                <me>
                    \sum_{n \in S_{x, m}} \frac{1}{n^s} = \prod_{p \leq x} \sum_{j=0}^m \frac{1}{p^{js}}
                </me>
                for all <m>x \geq 1, m \geq 0</m>. </p>

                <p>Now, we'll take a look at what happens to this sum as <m>x, m \to \infty</m>. As <m>m\to \infty</m>, the first observation to make is that the sums 
                <me>
                    \sum_{j=0}^m \frac{1}{p^{js}} \to \sum_{j=0}^\infty \frac{1}{p^{js}} = \frac{1}{1 - \frac{1}{p^s}} = (1 - \frac{1}{p^s})\inv
                </me>
                by the geometric series formula. An application of the dominated convergence theorem (when <m>\RE s > 1</m>) to push the limit into the product (remember that products are essentially sums under the log and that sums are integrals!) gets us
                <me>
                    \sum_{n \in \mathbb{N}} \frac{1}{n^s} = \lim_{x, m \to \infty} \sum_{n \in S_{x, m}} \frac{1}{n^s} = \prod_{p } (1 - \frac{1}{p^s})\inv.
                </me>

                    </p>
            </proof>
        </subsection>
        <subsection><title>Properties of the zeta function</title>
            <p>We'll now begin looking at some properties of the zeta function. We'll collect some of our results from the earlier discussion here as well.</p>
            <theorem><title>Properties of <m>\zeta</m></title>
                <p><ol>
                    <li>(analytic) <m>\zeta(s) = \sum_{n} \frac{1}{n^s}</m> is an analytic function on <m>\RE s \gt 1</m>.</li>
                    <li>(product formula) <me>\zeta(s) = \prod_{p} (1 - p^{-s})\inv</me>.</li>
                    <li>(zero-free region) <m>\zeta</m> has no zeros in <m>\{s: \RE s > 1\}</m>.</li>
                    <li>(meromorphic continuation) <m>\zeta</m> has a unique meromorphic continuation to <m>\C</m> with a simple pole at <m>s=1</m> and no other poles. Moreover, after removing the pole, <m>(s-1)\zeta(s)</m> is an entire function of order 1.</li>
                    <li>(functional equation)  <me>\zeta(s) = 2^s \pi^{s-1} \sin \frac{\pi s}{2} \Gamma(1-s) \zeta(1-s).</me></li>
                </ol></p>
            </theorem>

            <p>Facts 1 and 2 were proved in the earlier discussion. Fact 3 follows from the product formula for <m>\zeta</m>, as the product is absolutely convergent and has no zero terms . Facts 4 and 5 are more difficult - we'll first look at their implications, and then try to figure out where the functional equation came from.</p>

            <p>Let's calculate <m>\zeta(-1)</m> using the functional equation.
            <me>
                \zeta(-1) = 2^{-1} \pi^{-2} \sin \frac{-\pi }{2} \Gamma(2) \zeta(2) =\frac{-1}{2\pi^2} \frac{\pi^2}{6} = \frac{-1}{12}. 
            </me>
            If you want to dive into the chaos that this calculation unleashed a couple of years ago, you can look at <url href="https://terrytao.wordpress.com/2010/04/10/the-euler-maclaurin-formula-bernoulli-numbers-the-zeta-function-and-real-variable-analytic-continuation/"> this post</url> by Terry Tao or <url href="https://www.youtube.com/watch?v=YuIIjLr6vUA">this Mathologer video</url> in response to <url href="https://www.youtube.com/watch?v=w-I6XTVZXww">this Numberphile video</url> on the subject. </p>

            <p>Our first discussion is about where the zeros of <m>\zeta</m> are. (Note that we're abusing notation and using <m>\zeta</m> to represent the continuation of <m>\zeta</m> to <m>\C</m>.) We can probe this using the functional equation. Remember that <m>\Gamma</m> is a non-zero function with simple poles at <m>0</m> and the negative integers. <m>\sin \frac{\pi s}{2}</m> has simple zeros at all even integers, and we know that <m>\zeta</m> has only one pole, at <m>s=1</m>. So consider the product
            <me>
                \sin \frac{\pi s}{2} \Gamma(1-s) \zeta(1-s).
            </me>
            The poles of <m>\Gamma(1-s)</m>, which happen when <m>1 - s = 0, -1, -2, \ldots</m> or <m>s = 1, 2, 3, 4, \ldots</m> are being canceled into removable singularities by corresponding zeros in the product, with the exception of <m>s = 1</m>. The poles at the even values of <m>s</m> are being eaten by the simple zeros of <m>\sin \frac{\pi s}{2}</m>, which leaves poles at <m>s = 3, 5, 7, \ldots</m> that must be canceled by <m>\zeta(1-s)</m>. But this forces <m>\zeta(1-s)</m> to have simple zeros at <m>s = 3, 5, 7, \ldots</m>, which corresponds to <m>\zeta(s)</m> possessing simple zeros at <m>s = -2, -4, -6, \ldots</m>. These are called the <term>trivial zeros</term> of <m>\zeta</m>.</p>

            <p>The final subset of <m>\C</m> to consider the set <m>\{s: 0 \leq \RE s \leq 1\}</m>, which is called the <term>critical strip</term>. Here too we analyze the implications of the functional equation. It isn't hard to see that if <m>\zeta(s) = 0</m> in the critical strip, then so too must <m>\zeta(1-s) = 0</m> - that is, the zeros in the critical strip are reflected across the line <m>\RE s=1/2</m>.</p>

            <p>It might not be obvious, but the non-trivial zeros of <m>\zeta</m> have deep connections to other areas of mathematics. In fact, the main object of inquiry in our seminar, the prime number theorem, is essentially equivalent to a statement about the zeros of <m>\zeta</m>. <em>The prime number theorem is a consequence of the fact that <m>\zeta</m> has no zeros on the line <m>\RE s =1</m>.</em> We will prove this on our way to the prime number theorem itself.</p>

            <p>This leads us to what is broadly considered the most important unsolved problem in mathematics. Every known zero of <m>\zeta</m> in the critical strip is actually on the line <m>\RE s = 1/2</m>.</p>

            <conjecture><title>Riemann hypothesis</title>
                <p>All nontrivial zeros of <m>\zeta</m> are in the line <m>\RE s = 1/2</m>.</p>
            </conjecture>

            <p>Given the connection between the zeros of <m>\zeta</m> and the prime number theorem, one might expect quite a number of results that would follow from the resolution of the Riemann hypothesis. An outstanding discussion of some consequences can be found in this <url href="https://mathoverflow.net/questions/17209/consequences-of-the-riemann-hypothesis">mathoverflow post</url>.</p>

        </subsection>
        </section>

        <section><title>The prime number theorem</title>
            <subsection><title>Preliminaries</title>
            <p>Our first proof of the prime number theorem will run through a complex analytic argument due to Newman. The particular paper I'm referencing here is a very nice exposition of Newman's paper by D. Zagier. Tao's notes follow a similar line, but works through a different set of functions. </p>
            <aside>
                <p>See: <ol><li>D.J Newman, Simple Analytic Proof of the Prime Number Theorem. <em>Amer. Math. Monthly</em> 87 (1980)</li><li>D. Zagier. Newman's Short Proof of the Prime Number Theorem. <em>Amer. Math. Monthly</em> 104 (1997)</li></ol></p></aside> 

            <p>We aim to prove the following description of the asymptotic density of the primes in the integers. Let <m>\pi(x)</m> denote the number of primes less than or equal to <m>x</m>. We will use the notation <m>f \sim g</m> (that is, <m>f</m> and <m>g</m> are asymptotically equal) to mean <m>\lim_{x \to \infty} f(x)/g(x) = 1</m>. We will also use the order notation <m>g = \mathrm{O}(f)</m> as <m>x \to \infty</m> to mean that there exists some <m>C>0</m> so that <m>\abs{g(x)} \leq Cf(x)</m> for all sufficiently large <m>x</m>. (Every order argument we make in this section will be at infinity, so we may sometimes just write <m>g = \mathrm{O}(x)</m>.)  </p>

            <theorem><title>Prime number theorem</title>
            <p>
                <me>
                    \pi(x) \sim \frac{\log x}{x}.
                </me>
            </p></theorem>

            <p>Let us introduce our dramatis personae. Our primary character is, of course, the zeta function
                <me>
                    \zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}.
                </me>
            From the logarithmic derivative (<m>f\dd/f</m>) of <m>\zeta</m>, we'll consider the function
                <me>
                    \Phi(s) = \sum_p \frac{\log p}{p^s}.
                </me>
            Finally, our asymptotic prime checking will be done by the function
                <me>
                    \th(s) = \sum_{p \leq x} \log p.
                </me></p>

            <p>Essentially, the argument goes by showing that there can be no zeros of <m>\zeta</m> on the line <m>\RE(s) = 1</m>, and then using that fact to force an asymptotic estimate on <m>\th</m>. The steps to the proof are as follows:
                <ol>
                    <li><title>Product formula</title> Prove the product formula for <m>\zeta</m> for <m>\RE s > 1</m>. That is,
                    <me>
                        \zeta(s) = \prod_{p} (1 - p^{-s})\inv.
                    </me></li>
                    <li> <title>Continuation across the critical strip</title> Show that the function
                        <me>
                            \zeta(s) - \frac{1}{s -1}
                        </me>
                        has an analytic continuation to <m>\RE s > 0</m>.</li>
                    <li> <title>Order asymptotic for <m>\th</m></title> Show that 
                        <me>
                            \th(x) = \mathrm{O}(x).
                        </me>
                    </li>
                    <li><title>No zeros on <m>\RE s = 1</m></title> Show that 
                    <me>
                        \zeta(s) \neq 0 \text{ on } \RE s \geq 1
                    </me>
                    and that
                    <me>
                        \Phi(s) - \frac{1}{s-1} \text{ is holomorphic on } \RE s \geq 1.
                    </me></li>
                    <li><title>Integral estimate</title>
                        Show that 
                        <me>
                            \int_1^\infty \frac{\th(x) - x}{x^2} \, dx \text{ converges.}
                        </me></li>
                    <li> <title>Exact asymptotic for <m>\th</m></title> Show that 
                        <me>
                            \th(x) \sim x.
                        </me>
                    </li>
                    <li><title>Prime number theorem</title> Conclude that <me>\pi(x) \sim \frac{x}{\log x}.</me>
                    </li>
                </ol></p>

                <p>We will prove these as a series of theorems</p>

                <theorem><title>Step 1: product formula</title>
                <p>For <m>\RE s > 1</m>, 
                    <me>
                        \zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s} = \prod_{p} (1 - p^{-s})\inv.</me>
                    </p>
                </theorem>
                <p>This theorem was proved in the earlier section.</p>

                <theorem><title>Step II: continuation across the critical strip</title>
                <p>The function
                    <me>
                        \zeta(s) - \frac{1}{s-1}
                    </me>
                    analytically continues to the set <m>\RE s > 0</m>.</p>
                </theorem>
                <proof>
                    <p>
                        The idea is to write the function as a power series and show that it converges absolutely by comparison. Both functions are analytic on <m>\RE s > 1</m>, so we'll use that as a basis for our series. In order to leverage bounding in integral, note that we can write <m>1/(s-1)</m> in a sort of continuous <m>p</m>-series form via
                        <me>
                            \frac{1}{s-1} = \int_1^\infty \frac{1}{x^s}\, dx.
                        </me> 

                        Then,
                        <md>
                            <mrow>\zeta(s) - \frac{1}{s-1} \amp= \sum_{n=1}^\infty \frac{1}{n^s} - \int_1^\infty \frac{1}{x^s}\, dx</mrow>
                            <mrow>\amp= \sum_{n=1}^\infty \int_n^{n+1} (\frac{1}{n^s} - \frac{1}{x^s})\, dx.</mrow>
                        </md>
                    </p>

                    <p>The terms <m>1/n^s - 1/x^s</m> themselves look like the output of a definite integral - indeed,
                    <me>
                        \int_n^x \frac{s}{u^{s+1}}\, dx = \frac{1}{n^s} - \frac{1}{x^s}.
                    </me>
                    Then, invoking the ML inequality,
                    <md>
                        <mrow>\abs{ \int_n^{n+1} (\frac{1}{n^s} - \frac{1}{x^s})\, dx} \amp= \abs{s \int_n^{n+1} \int_n^x \frac{1}{u^{s+1}}\, du dx}</mrow>
                        <mrow>\amp\leq \max_{n \leq u \leq n+1} \abs{\frac{s}{u^{s+1}}}</mrow>
                        <mrow>\amp= \frac{\abs{s}}{n^{\RE s + 1}}.</mrow>
                    </md>
                   Thus, while we defined the series for <m>\RE s > 1</m>, the terms of the series will converge absolutely for <m>\RE s > 0</m>, (for example by successive application of the <m>M</m>-test on an appropriate family of half-disks).</p>
                </proof>

                <theorem><title>Step III: Order of <m>\th</m></title>
                    <p> For <m>x \to \infty</m>,
                        <me>
                            \th(x) = \sum_{p \leq x} \log p = \mathrm{O}(x).
                        </me>
                    </p>
                </theorem>
                <proof>
                   <p> The argument is combinatorial-esque. For <m>n \in \mathbb{N}</m>, we have
                    <md>
                        <mrow>2^{2n} = (1+1)^{2n} \amp= \binom{2n}{0} + \ldots \binom{2n}{2n} </mrow>
                        <mrow>\amp\geq \binom{2n}{n}</mrow>
                        <mrow> \amp\geq \prod_{n \leq p \leq 2n} p</mrow>
                        <mrow> \amp= \exp(\th(2n) - \th(n)).</mrow>
                    </md></p>

                    <p>This implies that
                        <me>
                            \th(x) - \th(\frac{x}{2}) \leq C x
                        </me>
                        for any <m>C > \log 2</m> for all <m>x > x_0</m> for some <m>x_0</m> whose choice depends on <m>C</m>. Now, given some large value of <m>x</m>, consider the sequence 
                        <me>
                            x, \frac{x}{2}, \frac{x}{4}, \ldots, \frac{x}{2^r} \geq x_0 \geq \frac{x}{2^{r+1}}.
                        </me>.
                        The corresponding inequalities are
                        <md>
                            <mrow>\th(x) - \th(\frac{x}{2}) \amp\leq Cx</mrow>
                            <mrow>\th(\frac{x}{2}) - \th(\frac{x}{4}) \amp\leq C\frac{x}{2}</mrow>
                            <mrow>\vdots</mrow>
                            <mrow>\th(\frac{x}{2^{r}})- \th(\frac{x}{2^r+1}) \amp\leq C\frac{x}{2^{r}}</mrow>.
                        </md>
                        Adding these results in the inequality
                        <me>
                            \th(x) - \th(\frac{x}{2^{r+1}}) \leq (1 + \frac{1}{2} + \ldots + \frac{1}{2^{r}})Cx \leq 2Cx,
                        </me>
                        and so, noting that <m>\th(\frac{x}{2^{r+1}}) \leq \th(x_0)</m>, we get
                        <me>
                            \th(x) \leq 2Cx + \th(x_0),
                        </me>
                        or in order notation 
                        <me>\th(x) = \mathrm{O}(x) \text{ as } x\to \infty</me> as <m>\th(x_0) = \mathrm{O}(1)</m>.</p>
                    </proof>

                    <p>We now arrive at the crucial step, which the assertion that <m>\zeta</m> has no zeros on the line <m>\RE s = 1</m>.</p>

                    <theorem><title>Step IV: zeros of <m>\zeta</m></title>
                        <p><m>\zeta(s) \neq 0</m> on <m>\RE s \geq 1</m>. Also, <m>\Phi(s) - 1/(s-1)</m> is holomorphic on <m>\RE s \geq 1</m>.</p>
                    </theorem>
                    <proof>
                        <p> Start with the assumption that <m>\RE s > 1</m>. Now compute the logarithmic derivative of <m>\zeta</m>:
                        <md>
                            <mrow> \frac{\zeta\dd}{\zeta} \amp= \frac{d}{ds} \log \zeta(s) = \frac{d}{ds} \log \prod_p (1 - p^{-s})\inv</mrow>
                            <mrow>\amp= \frac{d}{ds} \sum_p \log (1-p^{-s})\inv</mrow>
                            <mrow>\amp= -\sum_p \frac{d}{ds} \log (1-p^{-s})</mrow>
                            <mrow>\amp= -\sum_p \frac{\log p} {p^s(1-p^{-s})}</mrow>
                            <mrow>\amp= -(\sum_p \frac{\log p}{p^s} + \sum_p \frac{\log p}{p^s(p^s - 1)}).</mrow>
                            <mrow>\amp= -(\Phi(s) + \sum_p \frac{\log p}{p^s(p^s - 1)})</mrow>
                        </md>
                        This gives the identity
                        <me>
                            -\frac{\zeta\dd}{\zeta} = \Phi(s) + \sum_p\frac{\log p}{p^s(p^s - 1)}.
                        </me>
                        Notice that the series on the right hand side converges for <m>\RE s > \frac{1}{2}</m>. From Step II above, we know that <m>\zeta - \frac{1}{s-1}</m> is holomorphic on <m>\RE s > 0</m>, and so 
                        <me>
                            \zeta = (\zeta -\frac{1}{s-1}) + \frac{1}{s-1}
                        </me>
                        is meromorphic on <m>\RE s \geq 0</m> with a simple pole at <m>s = 1</m>. Likewise, <m>\zeta\dd</m> will be meromorphic with a pole at <m>s = 1</m> of order 2. Then <m>\zeta\dd/\zeta</m> is also a meromorphic function on <m>\RE s > 0</m> with poles at <m>s = 1</m> and at the zeros of <m>\zeta</m>, which implies for <m>\Phi</m>, which is
                        <men xml:id="eq-phiform">
                            \Phi = -\frac{\zeta\dd}{\zeta} -  \sum_p\frac{\log p}{p^s(p^s - 1)},
                        </men>
                        that we have a meromorphic extension of <m>\Phi</m> to <m>\RE s > \frac{1}{2}</m> with poles at <m>s = 1</m> and the zeros of <m>\zeta</m>.</p>

                        <p>Now let's analyze the zeros. First, because <m>\zeta(s) = \cc{\zeta(\cc s)}</m>, we see that if <m>s</m> is zero of <m>\zeta</m> then so is <m>\cc{s}</m>. Now let <m>a\in \R</m>. If <m>s_0 = 1 + ia</m> is a zero of <m>\zeta</m> of order <m>\mu \geq 0</m>, then <m>\zeta = (s - s_0)^\mu h(s)</m> for some holomorphic function <m>h</m> that is non-zero near <m>s_0</m>. Computing the logarithmic derivative gets us
                        <me>
                            -\frac{\zeta\dd}{\zeta} = -\frac{\mu}{s - s_0} + H(s)
                        </me>
                        for some function <m>H = \log h</m> holomorphic near <m>s_0</m>. The function <m>\Phi(s_0 + \eps)</m> then has a simple pole at <m>\eps = 0</m>, and by the residue theorem
                        <me>
                            \lim_{\eps \to 0} \eps \Phi(1 + \eps + ia) = -\mu.
                        </me> </p>

                        <p>Now, consider 
                            <me>
                                \Phi(1+\eps) = \sum_p \frac{\log p}{p^{1 + \eps}},
                            </me>
                            and note that the terms are positive for <m>\eps > 0</m>. Then
                            <me>
                                \sum_p \frac{\log p}{p^{1 + \eps}}(p^{\frac{ia}{2}} + p^{\frac{-ia}{2}})^2 \geq 0.
                            </me>
                            Multiplying this out gives
                            <me>
                                \Phi(1 + \eps -ia) + 2\Phi(1 + \eps) + \Phi(1 + \eps + ia) \geq 0.
                            </me>
                            From Part II, as noted above we have that <m>s = 1</m> is a simple pole of <m>-\zeta\dd/\zeta</m> with residue 1, and so 
                            <me>
                                \lim_{\eps \to 0} \eps \Phi(1_+ \eps) = 1.
                            </me>
                            Then 
                            <md>
                                <mrow>\amp\lim_{\eps \to 0} \eps(\Phi(1 + \eps -ia) + 2\Phi(1 + \eps) + \Phi(1 + \eps + ia))</mrow>
                                <mrow>\amp= -2\mu + 2 \geq 0</mrow>
                            </md>
                            and so <m>0 \leq \mu \leq 1</m>. As we intend to show that <m>\mu = 0</m>, we need more. So assume as well that <m>\zeta</m> has a zero at <m>s_1 = 1 \pm i2a</m> with order <m>\nu \geq 0</m>. (That is, we are admitting the possibility that there is no zero at those points.) Again, note that
                            <me>
                                \lim_{\eps \to 0} \eps \Phi(1 + \eps \pm i2a) = -\nu.
                            </me>
                            Then the same idea applied to
                            <me>
                                 \sum_p \frac{\log p}{p^{1 + \eps}}(p^{\frac{ia}{2}} + p^{\frac{-ia}{2}})^4 \geq 0
                             </me>
                             produces the equation 
                             <me>
                                6 - 8 \mu - 2 \nu \geq 0.
                            </me>
                            This requires that <m>\mu = 0</m> since <m>\mu, \nu \geq 0</m>. We have shown that if <m>\zeta</m> has a zero of the form <m>s_0 = 1 + ia</m>, then it must have order 0, and hence not be a zero. That is, <m>\zeta</m> has no zeros on the line <m>\RE s > 1</m>.</p>

                            <p>Finally, recall that the poles of <m>\Phi</m> are <m>s = 1</m> and the zeros of <m>\zeta</m>, none of which can lie on <m>\RE s = 1</m>. If we trace through the form of <m>\Phi</m> from <xref ref="eq-phiform"/> and the implications of Step II, we conclude that <m>\Phi - \frac{1}{s-1}</m> is holomorphic on <m>\RE s \geq 1</m>.</p>

                    </proof>
            </subsection>

        </section>

    </chapter>





</book>

</pretext>
